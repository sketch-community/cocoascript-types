{
  "abstract": [
    {
      "type": "text",
      "text": "Limit the effect of vImage operations to rectangular regions of interest."
    }
  ],
  "documentVersion": 0,
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/accelerate"
      ],
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/accelerate",
        "doc://com.apple.documentation/documentation/accelerate/vimage"
      ]
    ]
  },
  "identifier": {
    "url": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest",
    "interfaceLanguage": "occ"
  },
  "legacy_identifier": 3370675,
  "kind": "article",
  "metadata": {
    "title": "Applying vImage Operations to Regions of Interest",
    "role": "article",
    "roleHeading": "Article",
    "modules": [
      {
        "name": "Accelerate"
      }
    ]
  },
  "schemaVersion": {
    "major": 0,
    "minor": 1,
    "patch": 0
  },
  "sections": [],
  "variants": [
    {
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ],
      "paths": [
        "documentation/accelerate/applying_vimage_operations_to_regions_of_interest",
        "documentation/accelerate/vimage/applying_vimage_operations_to_regions_of_interest"
      ]
    },
    {
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ],
      "paths": [
        "documentation/accelerate/applying_vimage_operations_to_regions_of_interest",
        "documentation/accelerate/vimage/applying_vimage_operations_to_regions_of_interest"
      ]
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/accelerate": {
      "title": "Accelerate",
      "identifier": "doc://com.apple.documentation/documentation/accelerate",
      "url": "/documentation/accelerate",
      "type": "topic",
      "kind": "symbol",
      "role": "collection"
    },
    "doc://com.apple.documentation/documentation/accelerate/vimage": {
      "title": "vImage",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage",
      "kind": "article",
      "role": "collectionGroup",
      "url": "/documentation/accelerate/vimage",
      "abstract": [
        {
          "type": "text",
          "text": "Manipulate large images using the CPUâ€™s vector processor."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/1546176-vimagematrixmultiply_argb8888": {
      "title": "vImageMatrixMultiply_ARGB8888",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1546176-vimagematrixmultiply_argb8888",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1546176-vimagematrixmultiply_argb8888"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370698": {
      "title": "Listing 2",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370698",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370698"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370696": {
      "title": "Listing 3",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370696",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370696"
    },
    "doc://com.apple.documentation/documentation/accelerate/vimage_buffer/1545333-rowbytes": {
      "title": "rowBytes",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer/1545333-rowbytes",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/vimage_buffer/1545333-rowbytes"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370700": {
      "title": "Listing 4",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370700",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370700"
    },
    "doc://com.apple.documentation/documentation/accelerate/vimage_buffer": {
      "title": "vImage_Buffer",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/vimage_buffer"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370699": {
      "title": "Listing 5",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370699",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370699"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370697": {
      "title": "Listing 6",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370697",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370697"
    },
    "doc://com.apple.documentation/documentation/accelerate/converting_color_images_to_grayscale": {
      "title": "Converting Color Images to Grayscale",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/converting_color_images_to_grayscale",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/accelerate/converting_color_images_to_grayscale"
    },
    "link-media-3377262": {
      "identifier": "link-media-3377262",
      "type": "link",
      "title": "Figure 2",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3377262"
    },
    "media-3377262": {
      "identifier": "media-3377262",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 512
          },
          "url": "https://docs-assets.developer.apple.com/published/6d4d52497b/93c13e86-4a58-400a-bbe8-94f202de03e3.png"
        }
      ],
      "alt": "Photograph with a monochrome vertical strip.",
      "title": "Figure 2"
    },
    "doc://com.apple.documentation/documentation/accelerate/1515935-vimagetentconvolve_argb8888": {
      "title": "vImageTentConvolve_ARGB8888",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1515935-vimagetentconvolve_argb8888",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1515935-vimagetentconvolve_argb8888"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370717": {
      "title": "Listing 7",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370717",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370717"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370682": {
      "title": "Apply an In-Place Operation to an ROI",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370682",
      "kind": "article",
      "role": "subsection",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370682"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370716": {
      "title": "Listing 8",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370716",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370716"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370718": {
      "title": "Listing 9",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370718",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370718"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370720": {
      "title": "Listing 10",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370720",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370720"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370721": {
      "title": "Listing 11",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370721",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370721"
    },
    "link-media-3377259": {
      "identifier": "link-media-3377259",
      "type": "link",
      "title": "Figure 3",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3377259"
    },
    "media-3377259": {
      "identifier": "media-3377259",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 512
          },
          "url": "https://docs-assets.developer.apple.com/published/f4e9a26b46/380184bc-246c-4193-a8a5-cd31a8563aa2.png"
        }
      ],
      "alt": "Photograph with a blurred horizontal strip.",
      "title": "Figure 3"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370685": {
      "title": "Apply an Out-of-Place Operation to an ROI",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370685",
      "kind": "article",
      "role": "subsection",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370685"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371837": {
      "title": "Listing 12",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371837",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371837"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371839": {
      "title": "Listing 13",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371839",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371839"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371838": {
      "title": "Listing 14",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371838",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3371838"
    },
    "link-media-3377261": {
      "identifier": "link-media-3377261",
      "type": "link",
      "title": "Figure 4",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3377261"
    },
    "media-3377261": {
      "identifier": "media-3377261",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 179
          },
          "url": "https://docs-assets.developer.apple.com/published/f0cd4de767/70e6eb3f-b46e-44d0-a980-39c1fb5d8104.png"
        }
      ],
      "alt": "Cropped and blurred photograph.",
      "title": "Figure 4"
    },
    "link-media-3377260": {
      "identifier": "link-media-3377260",
      "type": "link",
      "title": "Figure 1",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3377260"
    },
    "media-3377260": {
      "identifier": "media-3377260",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 513
          },
          "url": "https://docs-assets.developer.apple.com/published/a127b3270c/96985970-5723-4798-8f5a-0b58e53462fd.png"
        }
      ],
      "alt": "Photograph with a blurred horizontal strip, and a monochrome vertical strip.",
      "title": "Figure 1"
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370695": {
      "title": "Listing 1",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370695",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370695"
    },
    "doc://com.apple.documentation/documentation/accelerate/creating_a_core_graphics_image_format": {
      "title": "Creating a Core Graphics Image Format",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/creating_a_core_graphics_image_format",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/creating_a_core_graphics_image_format",
      "abstract": [
        {
          "type": "text",
          "text": "Provide descriptions of Core Graphics image formats for conversions to and from vImage."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/creating_and_populating_buffers_from_core_graphics_images": {
      "title": "Creating and Populating Buffers from Core Graphics Images",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/creating_and_populating_buffers_from_core_graphics_images",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/creating_and_populating_buffers_from_core_graphics_images",
      "abstract": [
        {
          "type": "text",
          "text": "Initialize vImage buffers from Core Graphics images."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/creating_a_core_graphics_image_from_a_vimage_buffer": {
      "title": "Creating a Core Graphics Image from a vImage Buffer",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/creating_a_core_graphics_image_from_a_vimage_buffer",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/creating_a_core_graphics_image_from_a_vimage_buffer",
      "abstract": [
        {
          "type": "text",
          "text": "Create displayable representations of vImage buffers."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/building_a_basic_image-processing_workflow": {
      "title": "Building a Basic Image-Processing Workflow",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/building_a_basic_image-processing_workflow",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/building_a_basic_image-processing_workflow",
      "abstract": [
        {
          "type": "text",
          "text": "Resize an image with vImage."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_geometric_transforms_to_images": {
      "title": "Applying Geometric Transforms to Images",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_geometric_transforms_to_images",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/applying_geometric_transforms_to_images",
      "abstract": [
        {
          "type": "text",
          "text": "Reflect, shear, rotate, and scale image buffers using vImage."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/compositing_images_with_alpha_blending": {
      "title": "Compositing Images with Alpha Blending",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/compositing_images_with_alpha_blending",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/compositing_images_with_alpha_blending",
      "abstract": [
        {
          "type": "text",
          "text": "Combine two images by using alpha blending to create a single output."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/compositing_images_with_vimage_blend_modes": {
      "title": "Compositing Images with vImage Blend Modes",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/compositing_images_with_vimage_blend_modes",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/compositing_images_with_vimage_blend_modes",
      "abstract": [
        {
          "type": "text",
          "text": "Combine two images by using blend modes to create a single output."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest": {
      "title": "Applying vImage Operations to Regions of Interest",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/applying_vimage_operations_to_regions_of_interest",
      "abstract": [
        {
          "type": "text",
          "text": "Limit the effect of vImage operations to rectangular regions of interest."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance": {
      "title": "Optimizing Image-Processing Performance",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/optimizing_image-processing_performance",
      "abstract": [
        {
          "type": "text",
          "text": "Improve your app's performance by converting image buffer formats from interleaved to planar."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "url": "/documentation/technologies",
      "kind": "technologies",
      "title": "Technologies"
    }
  },
  "seeAlsoSections": [
    {
      "identifiers": [
        "doc://com.apple.documentation/documentation/accelerate/creating_a_core_graphics_image_format",
        "doc://com.apple.documentation/documentation/accelerate/creating_and_populating_buffers_from_core_graphics_images",
        "doc://com.apple.documentation/documentation/accelerate/creating_a_core_graphics_image_from_a_vimage_buffer",
        "doc://com.apple.documentation/documentation/accelerate/building_a_basic_image-processing_workflow",
        "doc://com.apple.documentation/documentation/accelerate/applying_geometric_transforms_to_images",
        "doc://com.apple.documentation/documentation/accelerate/compositing_images_with_alpha_blending",
        "doc://com.apple.documentation/documentation/accelerate/compositing_images_with_vimage_blend_modes",
        "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance",
        "doc://com.apple.documentation/documentation/accelerate/vimage"
      ],
      "title": "Image Processing Essentials",
      "generated": true
    }
  ],
  "primaryContentSections": [
    {
      "kind": "content",
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "You can apply vImage operationsâ€”for example, blurs and color transformsâ€”to specified rectangular areas in an image, commonly referred to as "
            },
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "regions of interest"
                }
              ]
            },
            {
              "type": "text",
              "text": " (ROI). Limiting the effect of an operation is useful when, for example, you want to overlay user interface elements on top of a blurred part of an image to make them stand out."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "This article walks you through three approaches to apply operations to an ROI:"
            }
          ]
        },
        {
          "type": "unorderedList",
          "items": [
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Apply an in-place operation to an ROI."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Apply an out-of-place operation to an ROI."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Crop and apply an out-of-place operation to an ROI."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following image is an example of the effects possible when you use the techniques in this article. The image shows a single photograph with a landscape format ROI that's been blurred, and a portrait format ROI that's been desaturated."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3377260",
              "metadata": {
                "anchor": "3377260",
                "title": "Figure 1"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The functions described in this article are all implemented as extensions to the "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer"
            },
            {
              "type": "text",
              "text": " structure. This means it's extremely simple to use them; the image above was created with just two function calls:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "// source is a `vImage_Buffer` that contains an ARGB8888 image.",
            "",
            "source.desaturate_ARGB8888(regionOfInterest: CGRect( ... ))",
            "",
            "let blurred = source.blurred_ARGB8888(regionOfInterest: CGRect( ... ),",
            "                                      blurRadius: 100)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370695",
            "title": "Listing 1"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": []
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Apply an In-Place Operation to an ROI",
          "anchor": "3370682"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "For vImage routines that operate in-place (that is, the operation mutates the source buffer's contents), create a mutating function that applies that routine to an ROI. The following code is the function header for a desaturation function based around "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1546176-vimagematrixmultiply_argb8888"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "extension vImage_Buffer {",
            "",
            "    mutating func desaturate_ARGB8888(regionOfInterest roi: CGRect) {"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370698",
            "title": "Listing 2"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Next, check that the supplied ROI is within the bounds of the buffer:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        guard Int(roi.maxX) <= width && Int(roi.maxY) <= height &&",
            "            Int(roi.minX) >= 0 && Int(roi.minY) >= 0 else {",
            "                print(\"ROI is out of bounds.\")",
            "                return",
            "        }"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370696",
            "title": "Listing 3"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Calculate the first pixel in the source buffer for the ROI. To find this pixel, multiply the "
            },
            {
              "type": "codeVoice",
              "code": "y"
            },
            {
              "type": "text",
              "text": " origin of the ROI by the source buffer's "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer/1545333-rowbytes"
            },
            {
              "type": "text",
              "text": ", added to the "
            },
            {
              "type": "codeVoice",
              "code": "x"
            },
            {
              "type": "text",
              "text": " origin of the ROI multiplied by the number of bytes that describe each pixel:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        let bytesPerPixel = 4",
            "        ",
            "        let start = Int(roi.origin.y) * rowBytes +",
            "            Int(roi.origin.x) * bytesPerPixel"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370700",
            "title": "Listing 4"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Use this start value to define a second "
            },
            {
              "type": "reference",
              "isActive": false,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer"
            },
            {
              "type": "text",
              "text": " structure, that references the source buffer's data (that is, the image data is shared between both buffers and not copied) with a size that equals the ROI:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        var desaturationBuffer = vImage_Buffer(data: data.advanced(by: start),",
            "                                               height: vImagePixelCount(roi.height),",
            "                                               width: vImagePixelCount(roi.width),",
            "                                               rowBytes: rowBytes)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370699",
            "title": "Listing 5"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "codeVoice",
              "code": "desaturationBuffer"
            },
            {
              "type": "text",
              "text": " is now a reference to the data in the source buffer defined by the supplied ROI. Calling "
            },
            {
              "type": "reference",
              "isActive": false,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1546176-vimagematrixmultiply_argb8888"
            },
            {
              "type": "text",
              "text": " with "
            },
            {
              "type": "codeVoice",
              "code": "desaturationBuffer"
            },
            {
              "type": "text",
              "text": " as the source and destination performs the matrix multiplication on the pixels in the ROI:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        let divisor: Int32 = 0x1000",
            "        ",
            "        let desaturationMatrix = [",
            "            0.0722, 0.0722, 0.0722, 0,",
            "            0.7152, 0.7152, 0.7152, 0,",
            "            0.2126, 0.2126, 0.2126, 0,",
            "            0,      0,      0,      1",
            "            ].map {",
            "                return Int16($0 * Float(divisor))",
            "        }",
            "        ",
            "        let error = vImageMatrixMultiply_ARGB8888(&desaturationBuffer,",
            "                                                  &desaturationBuffer,",
            "                                                  desaturationMatrix,",
            "                                                  divisor,",
            "                                                  nil, nil,",
            "                                                  vImage_Flags(kvImageNoFlags))",
            "        ",
            "        if error != kvImageNoError {",
            "            print(\"Error: \\(error)\")",
            "        }",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370697",
            "title": "Listing 6"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "To learn more about using matrix multiplication to convert color images to grayscale, see "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/converting_color_images_to_grayscale"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following shows the result of desaturating an ROI:"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3377262",
              "metadata": {
                "anchor": "3377262",
                "title": "Figure 2"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": []
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Apply an Out-of-Place Operation to an ROI",
          "anchor": "3370685"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "For vImage routines that don't operate in-place, create a non-mutating function that applies that routine to an ROI and returns a new "
            },
            {
              "type": "reference",
              "isActive": false,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer"
            },
            {
              "type": "text",
              "text": " structure that contains the result."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following code is the function header for a blurring function based around "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1515935-vimagetentconvolve_argb8888"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "extension vImage_Buffer {",
            "    ",
            "    func blurred_ARGB8888(regionOfInterest roi: CGRect,",
            "                          blurRadius: Int) -> vImage_Buffer? {"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370717",
            "title": "Listing 7"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Perform the same check as "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370682"
            },
            {
              "type": "text",
              "text": " on the ROI size:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        guard Int(roi.maxX) <= width && Int(roi.maxY) <= height &&",
            "            Int(roi.minX) >= 0 && Int(roi.minY) >= 0 else {",
            "                print(\"ROI is out of bounds.\")",
            "                return nil",
            "        }"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370716",
            "title": "Listing 8"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "codeVoice",
              "code": "vImage_Buffer.blurred_ARGB8888(regionOfInterest:blurRadius:)"
            },
            {
              "type": "text",
              "text": " returns a buffer that is the same size as the source, and all pixels outside of the ROI will equal the respective pixels in the source. Create the buffer that the function returns, and copy the source pixels into the new buffer:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        guard var destination = try? vImage_Buffer(width: Int(width),",
            "                                                   height: Int(height),",
            "                                                   bitsPerPixel: 32) else {",
            "                                                    return nil",
            "        }",
            "        ",
            "        let bytesPerPixel = 4",
            "        ",
            "        withUnsafePointer(to: self) { src in",
            "            vImageCopyBuffer(src,",
            "                             &destination,",
            "                             bytesPerPixel,",
            "                             vImage_Flags(kvImageNoFlags))",
            "        }"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370718",
            "title": "Listing 9"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Using the same approach as "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370682"
            },
            {
              "type": "text",
              "text": ", calculate the start of the ROI, and create a buffer for the blur operation that references the copied pixels in "
            },
            {
              "type": "codeVoice",
              "code": "destination"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        let start = Int(roi.origin.y) * destination.rowBytes +",
            "            Int(roi.origin.x) * bytesPerPixel",
            "        ",
            "        var blurDestination = vImage_Buffer(data: destination.data.advanced(by: start),",
            "                                            height: vImagePixelCount(roi.height),",
            "                                            width: vImagePixelCount(roi.width),",
            "                                            rowBytes: destination.rowBytes)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370720",
            "title": "Listing 10"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The final step is to apply the blur using "
            },
            {
              "type": "reference",
              "isActive": false,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1515935-vimagetentconvolve_argb8888"
            },
            {
              "type": "text",
              "text": " to "
            },
            {
              "type": "codeVoice",
              "code": "blurDestination"
            },
            {
              "type": "text",
              "text": " and return the destination buffer:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        var error = kvImageNoError",
            "        ",
            "        withUnsafePointer(to: self) { src in",
            "            let blurDiameter = UInt32(blurRadius * 2 + 1)",
            "            error = vImageTentConvolve_ARGB8888(src,",
            "                                                &blurDestination,",
            "                                                nil,",
            "                                                vImagePixelCount(roi.origin.x),",
            "                                                vImagePixelCount(roi.origin.y),",
            "                                                blurDiameter, blurDiameter,",
            "                                                [0],",
            "                                                vImage_Flags(kvImageTruncateKernel))",
            "        }",
            "        ",
            "        if error != kvImageNoError {",
            "            destination.free()",
            "            print(\"Error: \\(error)\")",
            "            return nil",
            "        }",
            "        ",
            "        return destination",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3370721",
            "title": "Listing 11"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following shows the result of blurring an ROI:"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3377259",
              "metadata": {
                "anchor": "3377259",
                "title": "Figure 3"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": []
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Crop and Apply an Out-of-Place Operation to an ROI",
          "anchor": "3370683"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "When you need to apply an operation and crop to an ROI, create a simplified version of the function described in "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_vimage_operations_to_regions_of_interest#3370685"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following code is the function header and ROI size check for a function that blurs and crops to a specified ROI:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "extension vImage_Buffer {",
            "    ",
            "    func blurredCropped_ARGB8888(regionOfInterest roi: CGRect,",
            "                                 blurRadius: Int) -> vImage_Buffer? {",
            "        ",
            "        guard Int(roi.maxX) <= width && Int(roi.maxY) <= height &&",
            "            Int(roi.minX) >= 0 && Int(roi.minY) >= 0 else {",
            "                print(\"ROI is out of bounds.\")",
            "                return nil",
            "        }"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3371837",
            "title": "Listing 12"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "You will return a buffer the same size as the ROI, so create a destination buffer using the ROI's dimensions:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        guard var destination = try? vImage_Buffer(width: Int(roi.width),",
            "                                                   height: Int(roi.height),",
            "                                                   bitsPerPixel: 32) else {",
            "                                                    return nil",
            "        }"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3371839",
            "title": "Listing 13"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "In this blur and crop function, you don't need to calculate the start pixel. Instead, set the "
            },
            {
              "type": "codeVoice",
              "code": "srcOffsetToROI_X"
            },
            {
              "type": "text",
              "text": " and "
            },
            {
              "type": "codeVoice",
              "code": "srcOffsetToROI_Y"
            },
            {
              "type": "text",
              "text": " parameters of "
            },
            {
              "type": "reference",
              "isActive": false,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1515935-vimagetentconvolve_argb8888"
            },
            {
              "type": "text",
              "text": " to the ROI's origin:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "        var error = kvImageNoError",
            "        ",
            "        _ = withUnsafePointer(to: self) { src in",
            "            let blurDiameter = UInt32(blurRadius * 2 + 1)",
            "            error = vImageTentConvolve_ARGB8888(src,",
            "                                                &destination,",
            "                                                nil,",
            "                                                vImagePixelCount(roi.origin.x),",
            "                                                vImagePixelCount(roi.origin.y),",
            "                                                blurDiameter, blurDiameter,",
            "                                                [0],",
            "                                                vImage_Flags(kvImageTruncateKernel))",
            "        }",
            "        ",
            "        if error != kvImageNoError {",
            "            print(\"Error: \\(error)\")",
            "            return nil",
            "        }",
            "        ",
            "        return destination",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3371838",
            "title": "Listing 14"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following shows the result of blurring and cropping an ROI:"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3377261",
              "metadata": {
                "anchor": "3377261",
                "title": "Figure 4"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": []
        }
      ]
    }
  ],
  "legalNotices": {
    "copyright": "Copyright &copy; 2021 Apple Inc. All rights reserved.",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy"
  }
}
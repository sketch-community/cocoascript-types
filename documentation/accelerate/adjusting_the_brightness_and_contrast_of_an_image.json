{
  "abstract": [
    {
      "type": "text",
      "text": "Use a gamma function to apply a linear or exponential curve."
    }
  ],
  "documentVersion": 0,
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/accelerate"
      ],
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/accelerate",
        "doc://com.apple.documentation/documentation/accelerate/vimage"
      ]
    ]
  },
  "identifier": {
    "url": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image",
    "interfaceLanguage": "occ"
  },
  "legacy_identifier": 3024763,
  "kind": "article",
  "metadata": {
    "title": "Adjusting the Brightness and Contrast of an Image",
    "role": "sampleCode",
    "roleHeading": "Sample Code",
    "modules": [
      {
        "name": "Accelerate"
      }
    ],
    "platforms": [
      {
        "name": "iOS",
        "introducedAt": "13.0",
        "current": "14.3"
      },
      {
        "name": "Xcode",
        "introducedAt": "11.0",
        "current": "12.3"
      }
    ]
  },
  "schemaVersion": {
    "major": 1,
    "minor": 0,
    "patch": 0
  },
  "sections": [],
  "variants": [
    {
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ],
      "paths": [
        "documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image",
        "documentation/accelerate/vimage/adjusting_the_brightness_and_contrast_of_an_image"
      ]
    },
    {
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ],
      "paths": [
        "documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image",
        "documentation/accelerate/vimage/adjusting_the_brightness_and_contrast_of_an_image"
      ]
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/accelerate": {
      "title": "Accelerate",
      "identifier": "doc://com.apple.documentation/documentation/accelerate",
      "url": "/documentation/accelerate",
      "type": "topic",
      "kind": "symbol",
      "role": "collection"
    },
    "doc://com.apple.documentation/documentation/accelerate/vimage": {
      "title": "vImage",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage",
      "url": "/documentation/accelerate/vimage",
      "type": "topic",
      "kind": "article",
      "role": "collectionGroup"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282922": {
      "title": "Listing 1",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282922",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282922"
    },
    "doc://com.apple.documentation/documentation/accelerate/1546371-vimagepiecewisegamma_planar8": {
      "title": "vImagePiecewiseGamma_Planar8",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1546371-vimagepiecewisegamma_planar8",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1546371-vimagepiecewisegamma_planar8"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282924": {
      "title": "Listing 2",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282924",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282924"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282925": {
      "title": "Listing 3",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282925",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282925"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282927": {
      "title": "Listing 4",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282927",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282927"
    },
    "doc://com.apple.documentation/documentation/accelerate/vimage_cgimageformat/1399088-bitsperpixel": {
      "title": "bitsPerPixel",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_cgimageformat/1399088-bitsperpixel",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/vimage_cgimageformat/1399088-bitsperpixel"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282928": {
      "title": "Listing 5",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282928",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282928"
    },
    "doc://com.apple.documentation/documentation/accelerate/1533062-vimageconvert_rgba8888torgb888": {
      "title": "vImageConvert_RGBA8888toRGB888",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1533062-vimageconvert_rgba8888torgb888",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1533062-vimageconvert_rgba8888torgb888"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282929": {
      "title": "Listing 6",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282929",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282929"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282931": {
      "title": "Listing 7",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282931",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282931"
    },
    "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance": {
      "title": "Optimizing Image-Processing Performance",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/optimizing_image-processing_performance"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282933": {
      "title": "Listing 8",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282933",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282933"
    },
    "doc://com.apple.documentation/documentation/accelerate/vimage_buffer/3241529-createcgimage": {
      "title": "createCGImage(format:flags:)",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer/3241529-createcgimage",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/vimage_buffer/3241529-createcgimage"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282934": {
      "title": "Listing 9",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282934",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282934"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282940": {
      "title": "Listing 10",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282940",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282940"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282941": {
      "title": "Listing 11",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282941",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282941"
    },
    "link-media-3282936": {
      "identifier": "link-media-3282936",
      "type": "link",
      "title": "Figure 1",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282936"
    },
    "media-3282936": {
      "identifier": "media-3282936",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 634,
            "height": 325
          },
          "url": "https://docs-assets.developer.apple.com/published/19bba9f4cd/dce06834-8c09-4011-9f71-4a38e97feade.png"
        }
      ],
      "alt": "On the left, a graph showing the equality between input and output values. On the right, an image of a basket full of mangoes, with linear adjustment applied.",
      "title": "Figure 1"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282942": {
      "title": "Listing 12",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282942",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282942"
    },
    "link-media-3282937": {
      "identifier": "link-media-3282937",
      "type": "link",
      "title": "Figure 2",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282937"
    },
    "media-3282937": {
      "identifier": "media-3282937",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 634,
            "height": 325
          },
          "url": "https://docs-assets.developer.apple.com/published/d4ad14cd57/5b342d0e-1528-4cb2-896d-e1d8343fdf62.png"
        }
      ],
      "alt": "On the left, a graph showing the linear relationship between input and output values. On the right, a washed-out version of the original photograph with linear adjustment applied.",
      "title": "Figure 2"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282943": {
      "title": "Listing 13",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282943",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282943"
    },
    "link-media-3282938": {
      "identifier": "link-media-3282938",
      "type": "link",
      "title": "Figure 3",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282938"
    },
    "media-3282938": {
      "identifier": "media-3282938",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 634,
            "height": 325
          },
          "url": "https://docs-assets.developer.apple.com/published/88e313a51f/a7d6ffa8-6c38-4dfd-ba24-d51e4f58971b.png"
        }
      ],
      "alt": "On the left, a graph showing the linear relationship between input and output values. On the right, a high contrast version of the original photograph with linear adjustment applied.",
      "title": "Figure 3"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282944": {
      "title": "Listing 14",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282944",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282944"
    },
    "link-media-3282939": {
      "identifier": "link-media-3282939",
      "type": "link",
      "title": "Figure 4",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282939"
    },
    "media-3282939": {
      "identifier": "media-3282939",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 637,
            "height": 325
          },
          "url": "https://docs-assets.developer.apple.com/published/d6606701a1/5715e3f8-8059-4132-8031-fb5d2b06d38d.png"
        }
      ],
      "alt": "On the left, a graph showing the linear relationship between input and output values. On the right, a negative version of the original photograph with linear adjustment applied.",
      "title": "Figure 4"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282949": {
      "title": "Listing 15",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282949",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282949"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282950": {
      "title": "Listing 16",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282950",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282950"
    },
    "link-media-3282946": {
      "identifier": "link-media-3282946",
      "type": "link",
      "title": "Figure 5",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282946"
    },
    "media-3282946": {
      "identifier": "media-3282946",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 634,
            "height": 325
          },
          "url": "https://docs-assets.developer.apple.com/published/19bba9f4cd/dce06834-8c09-4011-9f71-4a38e97feade.png"
        }
      ],
      "alt": "On the left, a graph showing the equality between input and output values. On the right, an unaffected photograph with exponential adjustment applied.",
      "title": "Figure 5"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282951": {
      "title": "Listing 17",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282951",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282951"
    },
    "link-media-3282947": {
      "identifier": "link-media-3282947",
      "type": "link",
      "title": "Figure 6",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282947"
    },
    "media-3282947": {
      "identifier": "media-3282947",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 634,
            "height": 325
          },
          "url": "https://docs-assets.developer.apple.com/published/09d582e4f3/25fdade5-c789-48db-8d14-379e9c7f9f4e.png"
        }
      ],
      "alt": "On the left, a graph showing the non linear relationship between input and output values. On the right, darkened version of original photograph with exponential adjustment applied.",
      "title": "Figure 6"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282952": {
      "title": "Listing 18",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282952",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282952"
    },
    "link-media-3282948": {
      "identifier": "link-media-3282948",
      "type": "link",
      "title": "Figure 7",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image#3282948"
    },
    "media-3282948": {
      "identifier": "media-3282948",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 634,
            "height": 325
          },
          "url": "https://docs-assets.developer.apple.com/published/7238a8c919/b777b1f4-3aa5-4f40-90c8-164b90db298c.png"
        }
      ],
      "alt": "On the left, a graph showing the non linear relationship between input and output values. On the right, a lightened version of original photograph with exponential adjustment applied.",
      "title": "Figure 7"
    },
    "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image": {
      "title": "Adjusting the Brightness and Contrast of an Image",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/accelerate/adjusting_the_brightness_and_contrast_of_an_image",
      "abstract": [
        {
          "type": "text",
          "text": "Use a gamma function to apply a linear or exponential curve."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/applying_tone_curve_adjustments_to_images": {
      "title": "Applying Tone Curve Adjustments to Images",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/applying_tone_curve_adjustments_to_images",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/accelerate/applying_tone_curve_adjustments_to_images",
      "abstract": [
        {
          "type": "text",
          "text": "Use the vImage library’s polynomial transform to apply tone curve adjustments to images."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/specifying_histograms_with_vimage": {
      "title": "Specifying Histograms with vImage",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/specifying_histograms_with_vimage",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/accelerate/specifying_histograms_with_vimage",
      "abstract": [
        {
          "type": "text",
          "text": "Calculate the histogram of one image and apply it to a second image."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/transform": {
      "title": "Transform",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/transform",
      "kind": "article",
      "role": "collectionGroup",
      "url": "/documentation/accelerate/transform",
      "abstract": [
        {
          "type": "text",
          "text": "Apply color transformations to images. "
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/histogram": {
      "title": "Histogram",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/histogram",
      "kind": "article",
      "role": "collectionGroup",
      "url": "/documentation/accelerate/histogram",
      "abstract": [
        {
          "type": "text",
          "text": "Calculate and or manipulate an image's histogram."
        }
      ]
    },
    "https://docs-assets.developer.apple.com/published/8e489f7d59/AdjustingTheBrightnessAndContrastOfAnImage.zip": {
      "type": "download",
      "identifier": "https://docs-assets.developer.apple.com/published/8e489f7d59/AdjustingTheBrightnessAndContrastOfAnImage.zip",
      "checksum": "b974e357fbf0b972565074d4d4d2785188710f7e9ca9aed090c4a7269d82ed550985966da44709450ee642f8d2fc4f35c83a58ae069fefd41db1988ca6e32738",
      "url": "https://docs-assets.developer.apple.com/published/8e489f7d59/AdjustingTheBrightnessAndContrastOfAnImage.zip"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "url": "/documentation/technologies",
      "kind": "technologies",
      "title": "Technologies"
    }
  },
  "sampleCodeDownload": {
    "action": {
      "overridingTitle": "Download",
      "type": "reference",
      "isActive": true,
      "identifier": "https://docs-assets.developer.apple.com/published/8e489f7d59/AdjustingTheBrightnessAndContrastOfAnImage.zip"
    }
  },
  "seeAlsoSections": [
    {
      "identifiers": [
        "doc://com.apple.documentation/documentation/accelerate/applying_tone_curve_adjustments_to_images",
        "doc://com.apple.documentation/documentation/accelerate/specifying_histograms_with_vimage",
        "doc://com.apple.documentation/documentation/accelerate/transform",
        "doc://com.apple.documentation/documentation/accelerate/histogram"
      ],
      "title": "Color and Tone Adjustment",
      "generated": true
    }
  ],
  "primaryContentSections": [
    {
      "kind": "content",
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "This sample code project uses the vImage piecewise gamma function to adjust the response curve (that is, the value of an output pixel based on the value of the corresponding input pixel) of an 8-bit ARGB image. Changing the shape of the response curve changes the brightness and contrast of an image."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "A piecewise gamma function allows you to apply a either linear or exponential response curve to pixels in an image based their value."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "This app displays a sample image and uses a segmented control to apply different preset linear (labelled L1 to L4) and exponential (labelled E1 to E3) response curves. In this sample, you’ll learn how different response curves affect an image by changing its brightness and contrast."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Define Response Curve Presets",
          "anchor": "3282956"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "This sample app defines a structure, "
            },
            {
              "type": "codeVoice",
              "code": "ResponseCurvePreset"
            },
            {
              "type": "text",
              "text": ", that contains the coefficients used by the linear function, the gamma used by the exponential function, and the boundary between the linear and exponential functions:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "struct ResponseCurvePreset {",
            "    let label: String",
            "    let boundary: Pixel_8",
            "    let linearCoefficients: [Float]",
            "    let gamma: Float",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282922",
            "title": "Listing 1"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "presets"
            },
            {
              "type": "text",
              "text": " array contains sample presets that apply different adjustments to the sample image."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "When the user changes the selected segment of the segmented control, the appropriate "
            },
            {
              "type": "codeVoice",
              "code": "preset"
            },
            {
              "type": "text",
              "text": " structure is passed to "
            },
            {
              "type": "codeVoice",
              "code": "getGammaCorrectedImage(preset:)"
            },
            {
              "type": "text",
              "text": " which applies the adjustment to the image and displays the result."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Define the Adjustment Parameters",
          "anchor": "3282957"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "You specify the division between linear and gamma adjustments by passing a boundary parameter to the piecewise gamma function, "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1546371-vimagepiecewisegamma_planar8"
            },
            {
              "type": "text",
              "text": ". The function uses the gamma curve to calculate the output value when the input value is greater than or equal to the boundary value. Otherwise, the function uses the linear curve."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "For 8-bit images, the boundary is a "
            },
            {
              "type": "codeVoice",
              "code": "Pixel_8"
            },
            {
              "type": "text",
              "text": " value, so a value of "
            },
            {
              "type": "codeVoice",
              "code": "0"
            },
            {
              "type": "text",
              "text": " indicates all pixels are gamma adjusted, a value of "
            },
            {
              "type": "codeVoice",
              "code": "255"
            },
            {
              "type": "text",
              "text": " indicates all pixels are linearly adjusted, and a value of "
            },
            {
              "type": "codeVoice",
              "code": "127"
            },
            {
              "type": "text",
              "text": " indicates all pixels with a value less than one-half are linearly adjusted."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let boundary: Pixel_8 = preset.boundary"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282924",
            "title": "Listing 2"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "You pass the linear and exponential coefficients (for example, the "
            },
            {
              "type": "codeVoice",
              "code": "a"
            },
            {
              "type": "text",
              "text": " and "
            },
            {
              "type": "codeVoice",
              "code": "b"
            },
            {
              "type": "text",
              "text": " in "
            },
            {
              "type": "codeVoice",
              "code": "(a * inputvalue) + b"
            },
            {
              "type": "text",
              "text": ") as arrays of floating-point values:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let linearCoefficients: [Float] = preset.linearCoefficients",
            "",
            "let exponentialCoefficients: [Float] = [1, 0, 0]",
            "let gamma: Float = preset.gamma"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282925",
            "title": "Listing 3"
          }
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Remove the Alpha Channel",
          "anchor": "3282958"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "vImagePiecewiseGamma_Planar8"
            },
            {
              "type": "text",
              "text": " function used in this sample treats the interleaved RGBA buffer as a single plane, applying the same gamma adjustment to all channels—including the alpha channel. Adjusting the response curve of the alpha channel changes transparency properties. To avoid this, convert the RGBA source image to RGB and apply the adjustment to that."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Create the RGB version of the source image by creating a 3-channel, 8-bit format:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "lazy var rgbFormat: vImage_CGImageFormat = {",
            "    return vImage_CGImageFormat(",
            "        bitsPerComponent: 8,",
            "        bitsPerPixel: 8 * 3,",
            "        colorSpace: CGColorSpaceCreateDeviceRGB(),",
            "        bitmapInfo: CGBitmapInfo(rawValue: CGImageAlphaInfo.none.rawValue),",
            "        renderingIntent: .defaultIntent)!",
            "}()"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282927",
            "title": "Listing 4"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Create a 3-channel destination buffer using the source buffer’s dimensions and the RGB format’s "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_cgimageformat/1399088-bitsperpixel"
            },
            {
              "type": "text",
              "text": " value:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "lazy var destinationBuffer: vImage_Buffer = {",
            "    ",
            "    guard let destinationBuffer = try? vImage_Buffer(width: Int(sourceBuffer.width),",
            "                                                     height: Int(sourceBuffer.height),",
            "                                                     bitsPerPixel: rgbFormat.bitsPerPixel) else {",
            "                                                        fatalError(\"Unable to create destinastion buffer.\")",
            "    }",
            "    ",
            "    return destinationBuffer",
            "}()"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282928",
            "title": "Listing 5"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Use the "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1533062-vimageconvert_rgba8888torgb888"
            },
            {
              "type": "text",
              "text": " to populate the destination with only the color channels:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "vImageConvert_RGBA8888toRGB888(&sourceBuffer,",
            "                               &destinationBuffer,",
            "                               vImage_Flags(kvImageNoFlags))"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282929",
            "title": "Listing 6"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "On return, "
            },
            {
              "type": "codeVoice",
              "code": "destinationBuffer"
            },
            {
              "type": "text",
              "text": " contains the red, green, and blue channels of "
            },
            {
              "type": "codeVoice",
              "code": "sourceBuffer"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Prepare the Buffers",
          "anchor": "3282959"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1546371-vimagepiecewisegamma_planar8"
            },
            {
              "type": "text",
              "text": " function expects planar buffers. Create a planar representation of the RGB buffer that is three times its width to pass to the piecewise gamma function:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "var planarDestination = vImage_Buffer(data: destinationBuffer.data,",
            "                                      height: destinationBuffer.height,",
            "                                      width: destinationBuffer.width * 3,",
            "                                      rowBytes: destinationBuffer.rowBytes)",
            ""
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282931",
            "title": "Listing 7"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "This approach applies the same adjustment to all three channels of your interleaved buffer. If you need to separate the interleaved buffer to individual planar buffers (for example, to adjust individual colors with different parameters), see "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Apply the Adjustment",
          "anchor": "3282960"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "With the parameters and buffers prepared, call "
            },
            {
              "type": "codeVoice",
              "code": "vImagePiecewiseGamma_Planar8"
            },
            {
              "type": "text",
              "text": " to apply the adjustment. Because the piecewise gamma function can work in place, you can use "
            },
            {
              "type": "codeVoice",
              "code": "planarDestination"
            },
            {
              "type": "text",
              "text": " as the source and destination:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "vImagePiecewiseGamma_Planar8(&planarDestination,",
            "                             &planarDestination,",
            "                             exponentialCoefficients,",
            "                             gamma,",
            "                             linearCoefficients,",
            "                             boundary,",
            "                             vImage_Flags(kvImageNoFlags))"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282933",
            "title": "Listing 8"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "To create the image, pass the destination buffer and RGB format to "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage_buffer/3241529-createcgimage"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let result = try? destinationBuffer.createCGImage(format: rgbFormat)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282934",
            "title": "Listing 9"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following explains the presets in more detail:"
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Apply Linear Adjustment",
          "anchor": "3282961"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following presets use the linear adjustment (that is, "
            },
            {
              "type": "codeVoice",
              "code": "boundary"
            },
            {
              "type": "text",
              "text": " is 255). The output value for each pixel is calculated as:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "(linearCoefficients[0] * inputValue) + linearCoefficients[1]"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282940",
            "title": "Listing 10"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "L1"
            },
            {
              "type": "text",
              "text": " preset returns each pixel unchanged:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "ResponseCurvePreset(label: \"L1\",",
            "                    boundary: 255,",
            "                    linearCoefficients: [1, 0],",
            "                    gamma: 0),"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282941",
            "title": "Listing 11"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3282936",
              "metadata": {
                "anchor": "3282936",
                "title": "Figure 1"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "L2"
            },
            {
              "type": "text",
              "text": " preset returns a washed out image where blacks are transformed to grays. When the input value is "
            },
            {
              "type": "codeVoice",
              "code": "0"
            },
            {
              "type": "text",
              "text": ", the output value is "
            },
            {
              "type": "codeVoice",
              "code": "0.5"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "ResponseCurvePreset(label: \"L2\",",
            "                    boundary: 255,",
            "                    linearCoefficients: [0.5, 0.5],",
            "                    gamma: 0),"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282942",
            "title": "Listing 12"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3282937",
              "metadata": {
                "anchor": "3282937",
                "title": "Figure 2"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "L3"
            },
            {
              "type": "text",
              "text": " preset returns a an image with a lot of contrast. When the input value is less than one-third, the output value is "
            },
            {
              "type": "codeVoice",
              "code": "0"
            },
            {
              "type": "text",
              "text": "; when the input value is greater than two-thirds, the output value is "
            },
            {
              "type": "codeVoice",
              "code": "1"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "ResponseCurvePreset(label: \"L3\",",
            "                    boundary: 255,",
            "                    linearCoefficients: [3, -1],",
            "                    gamma: 0),"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282943",
            "title": "Listing 13"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3282938",
              "metadata": {
                "anchor": "3282938",
                "title": "Figure 3"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "L4"
            },
            {
              "type": "text",
              "text": " preset returns a negative version of the image. When the input value is "
            },
            {
              "type": "codeVoice",
              "code": "1"
            },
            {
              "type": "text",
              "text": ", the output value is "
            },
            {
              "type": "codeVoice",
              "code": "0"
            },
            {
              "type": "text",
              "text": "; when the input value is "
            },
            {
              "type": "codeVoice",
              "code": "0"
            },
            {
              "type": "text",
              "text": ", the output value is "
            },
            {
              "type": "codeVoice",
              "code": "1"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "ResponseCurvePreset(label: \"L4\",",
            "                    boundary: 255,",
            "                    linearCoefficients: [-1, 1],",
            "                    gamma: 0),"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282944",
            "title": "Listing 14"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3282939",
              "metadata": {
                "anchor": "3282939",
                "title": "Figure 4"
              }
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Apply Exponential Adjustment",
          "anchor": "3282962"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following presets use the exponential adjustment (that is, "
            },
            {
              "type": "codeVoice",
              "code": "boundary"
            },
            {
              "type": "text",
              "text": " is 0). The output value for each pixel is calculated as:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "pow((exponentialCoefficients[0] * inputValue) + ",
            "     exponentialCoefficients[1], gamma) + ",
            "     exponentialCoefficients[2]"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282949",
            "title": "Listing 15"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "In these examples, "
            },
            {
              "type": "codeVoice",
              "code": "exponentialCoefficients"
            },
            {
              "type": "text",
              "text": " is defined as "
            },
            {
              "type": "codeVoice",
              "code": "[1, 0, 0]"
            },
            {
              "type": "text",
              "text": " and the calculation can be simplified to "
            },
            {
              "type": "codeVoice",
              "code": "pow(inputValue, gamma)"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "E1"
            },
            {
              "type": "text",
              "text": " preset returns each pixel unchanged:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "ResponseCurvePreset(label: \"E1\",",
            "                    boundary: 0,",
            "                    linearCoefficients: [1, 0],",
            "                    gamma: 1),"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282950",
            "title": "Listing 16"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3282946",
              "metadata": {
                "anchor": "3282946",
                "title": "Figure 5"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "E2"
            },
            {
              "type": "text",
              "text": " preset has an overall darkening effect:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "ResponseCurvePreset(label: \"E2\",",
            "                    boundary: 0,",
            "                    linearCoefficients: [1, 0],",
            "                    gamma: 2.2),"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282951",
            "title": "Listing 17"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3282947",
              "metadata": {
                "anchor": "3282947",
                "title": "Figure 6"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "E3"
            },
            {
              "type": "text",
              "text": " preset has an overall lightening effect:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "ResponseCurvePreset(label: \"E3\",",
            "                    boundary: 0,",
            "                    linearCoefficients: [1, 0],",
            "                    gamma: 1 / 2.2)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3282952",
            "title": "Listing 18"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3282948",
              "metadata": {
                "anchor": "3282948",
                "title": "Figure 7"
              }
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Correct Gamma Before Applying Operations",
          "anchor": "3282963"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Many vImage operations—such as convolution and scaling—provide optimal results when working on images with a linear response curve. If you are working with nonlinear images—such as sRGB—consider converting them to a linear color space by applying a reciprocal gamma (such as "
            },
            {
              "type": "codeVoice",
              "code": "1/2.2"
            },
            {
              "type": "text",
              "text": "), performing the operation, and converting them back to their original domain by applying the original gamma (such as "
            },
            {
              "type": "codeVoice",
              "code": "2.2"
            },
            {
              "type": "text",
              "text": ")."
            }
          ]
        }
      ]
    }
  ],
  "legalNotices": {
    "copyright": "Copyright &copy; 2020 Apple Inc. All rights reserved.",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy"
  }
}
{
  "abstract": [
    {
      "type": "text",
      "text": "Filter an image by convolving it with custom and high-speed kernels."
    }
  ],
  "documentVersion": 0,
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/accelerate"
      ],
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/accelerate",
        "doc://com.apple.documentation/documentation/accelerate/vimage"
      ]
    ]
  },
  "identifier": {
    "url": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image",
    "interfaceLanguage": "occ"
  },
  "legacy_identifier": 3021418,
  "kind": "article",
  "metadata": {
    "title": "Blurring an Image",
    "role": "sampleCode",
    "roleHeading": "Sample Code",
    "modules": [
      {
        "name": "Accelerate"
      }
    ],
    "platforms": [
      {
        "name": "iOS",
        "introducedAt": "14.0",
        "current": "15.2"
      },
      {
        "name": "iPadOS",
        "introducedAt": "14.0",
        "current": "15.2"
      },
      {
        "name": "Xcode",
        "introducedAt": "12.3",
        "current": "13.2"
      }
    ]
  },
  "schemaVersion": {
    "major": 0,
    "minor": 1,
    "patch": 0
  },
  "sections": [],
  "variants": [
    {
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ],
      "paths": [
        "documentation/accelerate/blurring_an_image",
        "documentation/accelerate/vimage/blurring_an_image"
      ]
    },
    {
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ],
      "paths": [
        "documentation/accelerate/blurring_an_image",
        "documentation/accelerate/vimage/blurring_an_image"
      ]
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/accelerate": {
      "title": "Accelerate",
      "identifier": "doc://com.apple.documentation/documentation/accelerate",
      "url": "/documentation/accelerate",
      "type": "topic",
      "kind": "symbol",
      "role": "collection"
    },
    "doc://com.apple.documentation/documentation/accelerate/vimage": {
      "title": "vImage",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/vimage",
      "url": "/documentation/accelerate/vimage",
      "type": "topic",
      "kind": "article",
      "role": "collectionGroup"
    },
    "link-media-3725635": {
      "identifier": "link-media-3725635",
      "type": "link",
      "title": "Figure 3",
      "url": "/documentation/accelerate/blurring_an_image#3725635"
    },
    "media-3725635": {
      "identifier": "media-3725635",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 320,
            "height": 63
          },
          "url": "https://docs-assets.developer.apple.com/published/10f1640f53/f6b667d2-0839-48cf-971c-9ca4d698a05f.png"
        }
      ],
      "alt": "Formula that describes the result of convolving with a box blur kernel.",
      "title": "Figure 3"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725637": {
      "title": "Listing 1",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725637",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725637"
    },
    "link-media-3725636": {
      "identifier": "link-media-3725636",
      "type": "link",
      "title": "Figure 4",
      "url": "/documentation/accelerate/blurring_an_image#3725636"
    },
    "media-3725636": {
      "identifier": "media-3725636",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 433
          },
          "url": "https://docs-assets.developer.apple.com/published/7b9a8ab79d/172e897e-9dce-4271-8b13-d03528f402b6.png"
        }
      ],
      "alt": "Photograph blurred using a 2D kernel based on a Hann window.",
      "title": "Figure 4"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725638": {
      "title": "Listing 2",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725638",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725638"
    },
    "doc://com.apple.documentation/documentation/accelerate/1515923-vimageconvolve_argb8888": {
      "title": "vImageConvolve_ARGB8888",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1515923-vimageconvolve_argb8888",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1515923-vimageconvolve_argb8888"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725639": {
      "title": "Listing 3",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725639",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725639"
    },
    "link-media-3725641": {
      "identifier": "link-media-3725641",
      "type": "link",
      "title": "Figure 5",
      "url": "/documentation/accelerate/blurring_an_image#3725641"
    },
    "media-3725641": {
      "identifier": "media-3725641",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 165
          },
          "url": "https://docs-assets.developer.apple.com/published/1236960933/87261148-f945-44ca-b7b6-91be9c8664cc.png"
        }
      ],
      "alt": "Formula that shows the outer product of a 7 by 1 vector and a 1 by 7 vector is the 7 by 7 matrix described in the previous section.",
      "title": "Figure 5"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725642": {
      "title": "Listing 4",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725642",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725642"
    },
    "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance": {
      "title": "Optimizing Image-Processing Performance",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance",
      "kind": "article",
      "role": "article",
      "url": "/documentation/accelerate/optimizing_image-processing_performance"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725643": {
      "title": "Listing 5",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725643",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725643"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725644": {
      "title": "Listing 6",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725644",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725644"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725645": {
      "title": "Listing 7",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725645",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725645"
    },
    "link-media-3725647": {
      "identifier": "link-media-3725647",
      "type": "link",
      "title": "Figure 6",
      "url": "/documentation/accelerate/blurring_an_image#3725647"
    },
    "media-3725647": {
      "identifier": "media-3725647",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 162,
            "height": 181
          },
          "url": "https://docs-assets.developer.apple.com/published/aa40c34b77/c0b09a04-4beb-45d7-8c66-57aa15147b80.png"
        }
      ],
      "alt": "Diagram showing how a box filter samples pixels in a surrounding rectangle.",
      "title": "Figure 6"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725651": {
      "title": "Listing 8",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725651",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725651"
    },
    "link-media-3725648": {
      "identifier": "link-media-3725648",
      "type": "link",
      "title": "Figure 7",
      "url": "/documentation/accelerate/blurring_an_image#3725648"
    },
    "media-3725648": {
      "identifier": "media-3725648",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 438
          },
          "url": "https://docs-assets.developer.apple.com/published/a20c903b4e/0e9e0563-50dd-4f87-9535-0f75416a488b.png"
        }
      ],
      "alt": "Photograph blurred using a box filter.",
      "title": "Figure 7"
    },
    "link-media-3725649": {
      "identifier": "link-media-3725649",
      "type": "link",
      "title": "Figure 8",
      "url": "/documentation/accelerate/blurring_an_image#3725649"
    },
    "media-3725649": {
      "identifier": "media-3725649",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 162,
            "height": 181
          },
          "url": "https://docs-assets.developer.apple.com/published/75b5e9cf33/0195ebe1-d95e-4ca8-911c-b36b92e9b9f8.png"
        }
      ],
      "alt": "Diagram showing how a tent filter samples pixels in a surrounding circle.",
      "title": "Figure 8"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725652": {
      "title": "Listing 9",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725652",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725652"
    },
    "link-media-3725650": {
      "identifier": "link-media-3725650",
      "type": "link",
      "title": "Figure 9",
      "url": "/documentation/accelerate/blurring_an_image#3725650"
    },
    "media-3725650": {
      "identifier": "media-3725650",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 431
          },
          "url": "https://docs-assets.developer.apple.com/published/2154fc1edf/d8e3bf2a-9d65-4fae-a562-662bb7d999d2.png"
        }
      ],
      "alt": "Photograph blurred using a tent filter.",
      "title": "Figure 9"
    },
    "doc://com.apple.documentation/documentation/accelerate/1578976-processing_flags/kvimagetruncatekernel": {
      "title": "kvImageTruncateKernel",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1578976-processing_flags/kvimagetruncatekernel",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1578976-processing_flags/kvimagetruncatekernel"
    },
    "doc://com.apple.documentation/documentation/accelerate/1515930-vimageconvolvemultikernel_argb88": {
      "title": "vImageConvolveMultiKernel_ARGB8888",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1515930-vimageconvolvemultikernel_argb88",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1515930-vimageconvolvemultikernel_argb88"
    },
    "doc://com.apple.documentation/documentation/accelerate/1515931-vimageconvolvemultikernel_argbff": {
      "title": "vImageConvolveMultiKernel_ARGBFFFF",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/1515931-vimageconvolvemultikernel_argbff",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/accelerate/1515931-vimageconvolvemultikernel_argbff"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725656": {
      "title": "Listing 10",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725656",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725656"
    },
    "link-media-3725654": {
      "identifier": "link-media-3725654",
      "type": "link",
      "title": "Figure 10",
      "url": "/documentation/accelerate/blurring_an_image#3725654"
    },
    "media-3725654": {
      "identifier": "media-3725654",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 256
          },
          "url": "https://docs-assets.developer.apple.com/published/f607d6f270/ecd3dc5b-f569-4934-a48b-212d41e19ae5.png"
        }
      ],
      "alt": "Diagram showing three kernels containing decreasing circles filled with ones surrounded by zeros.",
      "title": "Figure 10"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725657": {
      "title": "Listing 11",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image#3725657",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/accelerate/blurring_an_image#3725657"
    },
    "link-media-3725655": {
      "identifier": "link-media-3725655",
      "type": "link",
      "title": "Figure 11",
      "url": "/documentation/accelerate/blurring_an_image#3725655"
    },
    "media-3725655": {
      "identifier": "media-3725655",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 680,
            "height": 432
          },
          "url": "https://docs-assets.developer.apple.com/published/c104167a86/2be46148-582e-4a80-9763-be12fc29d4b3.png"
        }
      ],
      "alt": "Photograph blurred using multiple-kernel convolution.",
      "title": "Figure 11"
    },
    "link-media-3725631": {
      "identifier": "link-media-3725631",
      "type": "link",
      "title": "Figure 1",
      "url": "/documentation/accelerate/blurring_an_image#3725631"
    },
    "media-3725631": {
      "identifier": "media-3725631",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 384,
            "height": 281
          },
          "url": "https://docs-assets.developer.apple.com/published/09348c5368/a55b1477-4f79-4221-8aa1-ab3ae9f01f89.png"
        }
      ],
      "alt": "Diagram showing a 3 by 3 convolution kernel centered over a source pixel, highlighting the new pixel value.",
      "title": "Figure 1"
    },
    "link-media-3725632": {
      "identifier": "link-media-3725632",
      "type": "link",
      "title": "Figure 2",
      "url": "/documentation/accelerate/blurring_an_image#3725632"
    },
    "media-3725632": {
      "identifier": "media-3725632",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 320,
            "height": 75
          },
          "url": "https://docs-assets.developer.apple.com/published/0ba54ed4a3/3abacc20-ea86-4864-a9b4-821ab23b32b8.png"
        }
      ],
      "alt": "Formula that describes the result of convolving with an identity kernel.",
      "title": "Figure 2"
    },
    "doc://com.apple.documentation/documentation/accelerate/blurring_an_image": {
      "title": "Blurring an Image",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/blurring_an_image",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/accelerate/blurring_an_image",
      "abstract": [
        {
          "type": "text",
          "text": "Filter an image by convolving it with custom and high-speed kernels."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/adding_a_bokeh_effect": {
      "title": "Adding a Bokeh Effect",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/adding_a_bokeh_effect",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/accelerate/adding_a_bokeh_effect",
      "abstract": [
        {
          "type": "text",
          "text": "Simulate a bokeh effect by applying dilation."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/convolution": {
      "title": "Convolution",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/convolution",
      "kind": "article",
      "role": "collectionGroup",
      "url": "/documentation/accelerate/convolution",
      "abstract": [
        {
          "type": "text",
          "text": "Apply a convolution kernel to an image. "
        }
      ]
    },
    "doc://com.apple.documentation/documentation/accelerate/morphology": {
      "title": "Morphology",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/accelerate/morphology",
      "kind": "article",
      "role": "collectionGroup",
      "url": "/documentation/accelerate/morphology",
      "abstract": [
        {
          "type": "text",
          "text": "Dilate and erode images. "
        }
      ]
    },
    "https://docs-assets.developer.apple.com/published/390fd8b93e/BlurringAnImage.zip": {
      "type": "download",
      "identifier": "https://docs-assets.developer.apple.com/published/390fd8b93e/BlurringAnImage.zip",
      "checksum": "3a3b9c2c316c3ea68aa4f957f5e13c3952a348246ae542e21f7b1d2e030521bd0f62662af40c5b09db26f29361220dec73532c82333f558880704205a19b73d7",
      "url": "https://docs-assets.developer.apple.com/published/390fd8b93e/BlurringAnImage.zip"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "url": "/documentation/technologies",
      "kind": "technologies",
      "title": "Technologies"
    }
  },
  "sampleCodeDownload": {
    "action": {
      "overridingTitle": "Download",
      "type": "reference",
      "isActive": true,
      "identifier": "https://docs-assets.developer.apple.com/published/390fd8b93e/BlurringAnImage.zip"
    }
  },
  "seeAlsoSections": [
    {
      "identifiers": [
        "doc://com.apple.documentation/documentation/accelerate/adding_a_bokeh_effect",
        "doc://com.apple.documentation/documentation/accelerate/convolution",
        "doc://com.apple.documentation/documentation/accelerate/morphology"
      ],
      "title": "Convolution and Morphology",
      "generated": true
    }
  ],
  "primaryContentSections": [
    {
      "kind": "content",
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "This sample code project uses a variety of convolution techniques to blur images with custom kernels and built-in high-speed kernels. "
            },
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "Convolution"
                }
              ]
            },
            {
              "type": "text",
              "text": " is a common image-processing technique that changes the value of a pixel according to the values of its surrounding pixels. Many common image filters, such as blurring, detecting edges, sharpening, and embossing, derive from convolution."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "Kernels"
                }
              ]
            },
            {
              "type": "text",
              "text": " form the basis of convolution operations. Kernels are 1D or 2D grids of numbers that indicate the influence of a pixel’s neighbors on its final value. To calculate the value of each transformed pixel, add the products of each surrounding pixel value with the corresponding kernel value. During a convolution operation, the kernel passes over every pixel in the image, repeating this procedure, and then applies the effect to the entire image."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725631",
              "metadata": {
                "anchor": "3725631",
                "title": "Figure 1"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Kernels don’t need to have the same height and width, and can be 1D (that is, either the height or the width is 1) or 2D (that is, both the height and the width are greater than 1). When transforming a pixel, both dimensions must be odd numbers to center the kernel over the pixel."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The simplest kernel, known as an "
            },
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "identity kernel"
                }
              ]
            },
            {
              "type": "text",
              "text": ", contains a single value: 1. The following formula shows the result when applying the kernel to the central value in a grid of nine values. It multiplies the pixel by the central value in the convolution kernel, and then multiplies the surrounding pixel values by 9. The sum of these values is 0.5."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725632",
              "metadata": {
                "anchor": "3725632",
                "title": "Figure 2"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "An image remains unchanged when convolving it with an identity kernel."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Run the Sample",
          "anchor": "3725660"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "To change an image, select a blur filter from the bar button item’s menu of choices in the top right of the sample’s navigation bar."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Blur an Image with a 2D Kernel",
          "anchor": "3725661"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "A 2D kernel or box blur kernel returns the average value of the neighboring pixels. In this example, the kernel contains nine values and the result is the sum of 1 divided by 9 multiplied by each of the pixel values:"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725635",
              "metadata": {
                "anchor": "3725635",
                "title": "Figure 3"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Note that the sum of the values in the convolution kernel above is 1 — that is, the kernel is "
            },
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "normalized"
                }
              ]
            },
            {
              "type": "text",
              "text": ". If the sum of the values is greater than 1, the resulting image is brighter than the source. If the sum is less than 1, the resulting image is darker than the source."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "A more complex blurring kernel varies the influence of pixels according to their distance from the center of the kernel, and yields a smoother blurring effect. The following kernel (based on a Hann window) is suitable for use with an integer format (for example, "
            },
            {
              "type": "codeVoice",
              "code": "ARGB8888"
            },
            {
              "type": "text",
              "text": ") convolution:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let kernel2D: [Int16] = [",
            "    0,    0,    0,      0,      0,      0,      0,",
            "    0,    2025, 6120,   8145,   6120,   2025,   0,",
            "    0,    6120, 18496,  24616,  18496,  6120,   0,",
            "    0,    8145, 24616,  32761,  24616,  8145,   0,",
            "    0,    6120, 18496,  24616,  18496,  6120,   0,",
            "    0,    2025, 6120,   8145,   6120,   2025,   0,",
            "    0,    0,    0,      0,      0,      0,      0",
            "]"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725637",
            "title": "Listing 1"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The example below shows the result of blurring an image using "
            },
            {
              "type": "codeVoice",
              "code": "kernel2D"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725636",
              "metadata": {
                "anchor": "3725636",
                "title": "Figure 4"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The sample passes kernels as arrays of integers to the integer format convolution filters. To normalize an integer kernel, it passes a divisor to the function that is the sum of the elements of the kernel."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let divisor = kernel2D.map { Int32($0) }.reduce(0, +)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725638",
            "title": "Listing 2"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following example shows how to use "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1515923-vimageconvolve_argb8888"
            },
            {
              "type": "text",
              "text": " to perform a convolution and populate a destination buffer with the result. Note that in addition to passing the kernel, the sample also passes the kernel’s height and width using "
            },
            {
              "type": "codeVoice",
              "code": "kernelLength"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "vImageConvolve_ARGB8888(&sourceBuffer,",
            "                        &destinationBuffer,",
            "                        nil,",
            "                        0, 0,",
            "                        &kernel2D,",
            "                        UInt32(kernelLength),",
            "                        UInt32(kernelLength),",
            "                        divisor,",
            "                        nil,",
            "                        vImage_Flags(kvImageEdgeExtend))"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725639",
            "title": "Listing 3"
          }
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Blur an Image with a Separable Kernel",
          "anchor": "3725662"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "kernel2D"
            },
            {
              "type": "text",
              "text": " kernel described in the previous section is "
            },
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "separable"
                }
              ]
            },
            {
              "type": "text",
              "text": "; that is, it is the "
            },
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "outer product"
                }
              ]
            },
            {
              "type": "text",
              "text": " of a 1D horizontal kernel and a 1D vertical kernel. A separable kernel allows splitting of the 2D convolution into two 1D passes, resulting in faster processing times. The following formula shows the two vectors that form "
            },
            {
              "type": "codeVoice",
              "code": "kernel2D"
            },
            {
              "type": "text",
              "text": ":"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725641",
              "metadata": {
                "anchor": "3725641",
                "title": "Figure 5"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The separable convolution functions in vImage work on planar buffers. The sample uses the following code to create planar source and destination buffers, and to convert the interleaved source image to planar:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let componentCount = format.componentCount",
            "",
            "var argbSourcePlanarBuffers: [vImage_Buffer] = (0 ..< componentCount).map { _ in",
            "    guard let buffer = try? vImage_Buffer(width: Int(sourceBuffer.width),",
            "                                          height: Int(sourceBuffer.height),",
            "                                          bitsPerPixel: format.bitsPerComponent) else {",
            "                                            fatalError(\"Error creating source buffers.\")",
            "    }",
            "    ",
            "    return buffer",
            "}",
            "",
            "var argbDestinationPlanarBuffers: [vImage_Buffer] = (0 ..< componentCount).map { _ in",
            "    guard let buffer = try? vImage_Buffer(width: Int(sourceBuffer.width),",
            "                                          height: Int(sourceBuffer.height),",
            "                                          bitsPerPixel: format.bitsPerComponent) else {",
            "                                            fatalError(\"Error creating destination buffers.\")",
            "    }",
            "    ",
            "    return buffer",
            "}",
            "",
            "vImageConvert_ARGB8888toPlanar8(&sourceBuffer,",
            "                                &argbSourcePlanarBuffers[0],",
            "                                &argbSourcePlanarBuffers[1],",
            "                                &argbSourcePlanarBuffers[2],",
            "                                &argbSourcePlanarBuffers[3],",
            "                                vImage_Flags(kvImageNoFlags))"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725642",
            "title": "Listing 4"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "To learn more about working with planar buffers, see "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/optimizing_image-processing_performance"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "To avoid the overhead of applying convolution to the image’s alpha channel, the sample uses the following code to calculate the index of the alpha channel and copy alpha information to the corresponding destination buffer:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let alphaIndex: Int?",
            "",
            "let littleEndian = cgImage.byteOrderInfo == .order16Little ||",
            "                   cgImage.byteOrderInfo == .order32Little",
            "",
            "switch cgImage.alphaInfo {",
            "    case .first, .noneSkipFirst, .premultipliedFirst:",
            "        alphaIndex = littleEndian ? componentCount - 1 : 0",
            "    case .last, .noneSkipLast, .premultipliedLast:",
            "        alphaIndex = littleEndian ? 0 : componentCount - 1",
            "    default:",
            "        alphaIndex = nil",
            "}",
            "",
            "if let alphaIndex = alphaIndex {",
            "    do {",
            "        try argbSourcePlanarBuffers[alphaIndex].copy(destinationBuffer: &argbDestinationPlanarBuffers[alphaIndex],",
            "                                                     pixelSize: 1)",
            "    } catch {",
            "        fatalError(\"Error copying alpha buffer: \\(error.localizedDescription).\")",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725643",
            "title": "Listing 5"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The sample declares this 1D kernel with the following code:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let kernel1D: [Float] = [0, 45, 136, 181, 136, 45, 0]"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725644",
            "title": "Listing 6"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Note that the kernel for the separable convolution uses single-precision values. This allows for increased precision compared to the 2D integer convolution functions."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "To apply a blur using a pair of 1D kernels, the sample calls "
            },
            {
              "type": "codeVoice",
              "code": "vImageSepConvolve_Planar8"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "// Separable convolution pass.",
            " for index in 0 ..< componentCount where index != alphaIndex {",
            "    vImageSepConvolve_Planar8(&argbSourcePlanarBuffers[index],",
            "                              &argbDestinationPlanarBuffers[index],",
            "                              nil,",
            "                              0, 0,",
            "                              kernel1D, UInt32(kernel1D.count),",
            "                              kernel1D, UInt32(kernel1D.count),",
            "                              0, 0,",
            "                              vImage_Flags(kvImageEdgeExtend))",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725645",
            "title": "Listing 7"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The increase in speed from using two 1D kernels instead of a single 2D kernel is significant. For each pixel, the 2D pass requires "
            },
            {
              "type": "codeVoice",
              "code": "M * N"
            },
            {
              "type": "text",
              "text": " multiplications and additions (where "
            },
            {
              "type": "codeVoice",
              "code": "M"
            },
            {
              "type": "text",
              "text": " is the number of rows and "
            },
            {
              "type": "codeVoice",
              "code": "N"
            },
            {
              "type": "text",
              "text": " is the number of columns), but each 1D pass only requires "
            },
            {
              "type": "codeVoice",
              "code": "M + N"
            },
            {
              "type": "text",
              "text": " multiplications and additions."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Blur an Image with High-Speed Kernels",
          "anchor": "3725663"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "vImage provides two high-speed blurring convolutions for 8-bit images: a box filter and a tent filter. These blurs are equivalent to convolving with standard kernels, but the developer doesn’t need to supply the kernel. These functions are typically faster than performing an equivalent convolution with custom kernels."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The box filter returns the average pixel value in a rectangular region that surrounds the transformed pixel."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725647",
              "metadata": {
                "anchor": "3725647",
                "title": "Figure 6"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "This sample calls "
            },
            {
              "type": "codeVoice",
              "code": "vImageBoxConvolve_ARGB8888"
            },
            {
              "type": "text",
              "text": " to apply a box filter to an image."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "vImageBoxConvolve_ARGB8888(&sourceBuffer,",
            "                           &destinationBuffer,",
            "                           nil,",
            "                           0, 0,",
            "                           UInt32(kernelLength),",
            "                           UInt32(kernelLength),",
            "                           nil,",
            "                           vImage_Flags(kvImageEdgeExtend))"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725651",
            "title": "Listing 8"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Although the box filter is the fastest blur, the following example shows how it suffers from rectangular artifacts:"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725648",
              "metadata": {
                "anchor": "3725648",
                "title": "Figure 7"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The tent filter returns the weighted average of pixel values in a circular region that surrounds the pixel that vImage is transforming. "
            },
            {
              "type": "emphasis",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "Weighted average"
                }
              ]
            },
            {
              "type": "text",
              "text": " means that the influence of pixels on the result decreases the further they are away from the transformed pixel."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725649",
              "metadata": {
                "anchor": "3725649",
                "title": "Figure 8"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The sample calls "
            },
            {
              "type": "codeVoice",
              "code": "vImageTentConvolve_ARGB8888"
            },
            {
              "type": "text",
              "text": " to apply a tent filter to an image."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "vImageTentConvolve_ARGB8888(&sourceBuffer,",
            "                            &destinationBuffer,",
            "                            nil,",
            "                            0, 0,",
            "                            UInt32(kernelLength),",
            "                            UInt32(kernelLength),",
            "                            nil,",
            "                            vImage_Flags(kvImageEdgeExtend))"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725652",
            "title": "Listing 9"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following example shows the result of a tent filter. The result is a smoother blur, at the expense of being slightly slower to execute than the box filter."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725650",
              "metadata": {
                "anchor": "3725650",
                "title": "Figure 9"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Note that passing the "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1578976-processing_flags/kvimagetruncatekernel"
            },
            {
              "type": "text",
              "text": " flag to the high-speed kernels can significantly impact their performance. This flag is only necessary when vImage needs to restrict calculations to the portion of the kernel overlapping the image."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Blur an Image with Multiple Kernels",
          "anchor": "3725664"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "vImage can apply multiple kernels in a single convolution. The "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1515930-vimageconvolvemultikernel_argb88"
            },
            {
              "type": "text",
              "text": " and "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1515931-vimageconvolvemultikernel_argbff"
            },
            {
              "type": "text",
              "text": " functions make it possible to specify four separate kernels—one for each channel in the image."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "When using multiple kernels to apply image filters, vImage can operate on the red, green, blue, and alpha channels individually. For example, it can use multiple-kernel convolutions to resample the color channels of an image differently to compensate for the positioning of RGB phosphors on the screen. Since each of the four kernels can operate on a single channel, the vImage multiple-kernel convolution functions are available only to the interleaved image formats, "
            },
            {
              "type": "codeVoice",
              "code": "ARGB8888"
            },
            {
              "type": "text",
              "text": " and "
            },
            {
              "type": "codeVoice",
              "code": "ARGBFFFF"
            },
            {
              "type": "text",
              "text": "."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The four kernels for the convolution filters need to be the same size, but can accept padding with zeros to simulate smaller kernels. vImage is able to optimize individual passes, effectively cropping the zero padding."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The following code creates an array of four kernels, each containing a central circle of 1s of decreasing size:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let radius = kernelLength / 2",
            "let diameter = (radius * 2) + 1",
            "",
            "let kernels: [[Int16]] = (1 ... 4).map { index in",
            "    var kernel = [Int16](repeating: 0,",
            "                         count: diameter * diameter)",
            "    ",
            "    for x in 0 ..< diameter {",
            "        for y in 0 ..< diameter {",
            "            if hypot(Float(radius - x), Float(radius - y)) < Float(radius / index) {",
            "                kernel[y * diameter + x] = 1",
            "            }",
            "        }",
            "    }",
            "    ",
            "    return kernel",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725656",
            "title": "Listing 10"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "For example, with a kernel length of 17, the first three kernels from the code above contain the following values:"
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725654",
              "metadata": {
                "anchor": "3725654",
                "title": "Figure 10"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/accelerate/1515930-vimageconvolvemultikernel_argb88"
            },
            {
              "type": "text",
              "text": " performs the convolution."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "var divisors = kernels.map { return Int32($0.reduce(0, +)) }",
            "var biases: [Int32] = [0, 0, 0, 0]",
            "var backgroundColor: UInt8 = 0",
            "",
            "kernels[0].withUnsafeBufferPointer { zeroPtr in",
            "    kernels[1].withUnsafeBufferPointer { onePtr in",
            "        kernels[2].withUnsafeBufferPointer { twoPtr in",
            "            kernels[3].withUnsafeBufferPointer { threePtr in",
            "                ",
            "                var kernels = [zeroPtr.baseAddress, onePtr.baseAddress,",
            "                               twoPtr.baseAddress, threePtr.baseAddress]",
            "                ",
            "                _ = kernels.withUnsafeMutableBufferPointer { kernelsPtr in",
            "                    vImageConvolveMultiKernel_ARGB8888(&sourceBuffer,",
            "                                                       &destinationBuffer,",
            "                                                       nil,",
            "                                                       0, 0,",
            "                                                       kernelsPtr.baseAddress!,",
            "                                                       UInt32(diameter), UInt32(diameter),",
            "                                                       &divisors,",
            "                                                       &biases,",
            "                                                       &backgroundColor,",
            "                                                       vImage_Flags(kvImageEdgeExtend))",
            "                }",
            "            }",
            "        }",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3725657",
            "title": "Listing 11"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The example below shows the result of the multiple-kernel convolution. Note the color-fringing effect from applying different kernels to the different color channels."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-3725655",
              "metadata": {
                "anchor": "3725655",
                "title": "Figure 11"
              }
            }
          ]
        }
      ]
    }
  ],
  "legalNotices": {
    "copyright": "Copyright &copy; 2021 Apple Inc. All rights reserved.",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy"
  }
}
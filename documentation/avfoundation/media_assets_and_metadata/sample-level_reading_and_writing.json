{
  "abstract": [
    {
      "type": "text",
      "text": "Read and write media sample data."
    }
  ],
  "documentVersion": 0,
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/avfoundation",
        "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata"
      ]
    ]
  },
  "identifier": {
    "url": "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing",
    "interfaceLanguage": "occ"
  },
  "legacy_identifier": 3643893,
  "kind": "symbol",
  "metadata": {
    "title": "Sample-level Reading and Writing",
    "role": "collectionGroup",
    "modules": [
      {
        "name": "AVFoundation"
      }
    ]
  },
  "schemaVersion": {
    "major": 0,
    "minor": 1,
    "patch": 0
  },
  "sections": [],
  "variants": [
    {
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ],
      "paths": [
        "documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing"
      ]
    },
    {
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ],
      "paths": [
        "documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing"
      ]
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/avfoundation": {
      "title": "AVFoundation",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation",
      "url": "/documentation/avfoundation",
      "type": "topic",
      "kind": "symbol",
      "role": "collection"
    },
    "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata": {
      "title": "Media Assets and Metadata",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata",
      "url": "/documentation/avfoundation/media_assets_and_metadata",
      "type": "topic",
      "kind": "article",
      "role": "collectionGroup"
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetreader": {
      "title": "AVAssetReader",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetreader",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetreader",
      "abstract": [
        {
          "type": "text",
          "text": "A reader object used to obtain the media data of an asset, either file-based or consisting of an assemblage of media data from multiple sources."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetreaderoutput": {
      "title": "AVAssetReaderOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetreaderoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetreaderoutput",
      "abstract": [
        {
          "type": "text",
          "text": "An abstract class that defines an interface for reading a single collection of samples of a common media type from an asset reader object."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetreadertrackoutput": {
      "title": "AVAssetReaderTrackOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetreadertrackoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetreadertrackoutput",
      "abstract": [
        {
          "type": "text",
          "text": "An object that defines an interface for reading media data from a single track of an asset reader's asset."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetreaderaudiomixoutput": {
      "title": "AVAssetReaderAudioMixOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetreaderaudiomixoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetreaderaudiomixoutput",
      "abstract": [
        {
          "type": "text",
          "text": "An object that defines an interface for reading audio samples that result from mixing the audio from one or more tracks."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetreadervideocompositionoutput": {
      "title": "AVAssetReaderVideoCompositionOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetreadervideocompositionoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetreadervideocompositionoutput",
      "abstract": [
        {
          "type": "text",
          "text": "An object that reads video frames composited from the frames in one or more tracks of a reader's assets."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetreadersamplereferenceoutput": {
      "title": "AVAssetReaderSampleReferenceOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetreadersamplereferenceoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetreadersamplereferenceoutput",
      "abstract": [
        {
          "type": "text",
          "text": "An object that defines an interface for reading sample references from a single asset track."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetreaderoutputmetadataadaptor": {
      "title": "AVAssetReaderOutputMetadataAdaptor",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetreaderoutputmetadataadaptor",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetreaderoutputmetadataadaptor",
      "abstract": [
        {
          "type": "text",
          "text": "An object that defines an interface for reading metadata."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/writing_fragmented_mpeg-4_files_for_http_live_streaming": {
      "title": "Writing Fragmented MPEG-4 Files for HTTP Live Streaming",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/writing_fragmented_mpeg-4_files_for_http_live_streaming",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/writing_fragmented_mpeg-4_files_for_http_live_streaming",
      "abstract": [
        {
          "type": "text",
          "text": "Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/tagging_media_with_video_color_information": {
      "title": "Tagging Media with Video Color Information",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/tagging_media_with_video_color_information",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/tagging_media_with_video_color_information",
      "abstract": [
        {
          "type": "text",
          "text": "Inspect and set video color space information when writing and transcoding media."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/evaluating_an_app_s_video_color": {
      "title": "Evaluating an App’s Video Color",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/evaluating_an_app_s_video_color",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/evaluating_an_app_s_video_color",
      "abstract": [
        {
          "type": "text",
          "text": "Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avoutputsettingsassistant": {
      "title": "AVOutputSettingsAssistant",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avoutputsettingsassistant",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avoutputsettingsassistant",
      "abstract": [
        {
          "type": "text",
          "text": "An object that builds audio and video output settings dictionaries."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetwriter": {
      "title": "AVAssetWriter",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetwriter",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetwriter",
      "abstract": [
        {
          "type": "text",
          "text": "An object that writes media data to a container file."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinput": {
      "title": "AVAssetWriterInput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetwriterinput",
      "abstract": [
        {
          "type": "text",
          "text": "An object that appends media samples to a track in an asset writer’s output file."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputpixelbufferadaptor": {
      "title": "AVAssetWriterInputPixelBufferAdaptor",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputpixelbufferadaptor",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetwriterinputpixelbufferadaptor",
      "abstract": [
        {
          "type": "text",
          "text": "An object that appends video samples to an asset writer input."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputmetadataadaptor": {
      "title": "AVAssetWriterInputMetadataAdaptor",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputmetadataadaptor",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetwriterinputmetadataadaptor",
      "abstract": [
        {
          "type": "text",
          "text": "An object that appends timed metadata groups to an asset writer input."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputgroup": {
      "title": "AVAssetWriterInputGroup",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputgroup",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avassetwriterinputgroup",
      "abstract": [
        {
          "type": "text",
          "text": "A group of inputs with tracks that are mutually exclusive to each other for playback or processing."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing": {
      "title": "Sample-level Reading and Writing",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing",
      "kind": "article",
      "role": "collectionGroup",
      "url": "/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing",
      "abstract": [
        {
          "type": "text",
          "text": "Read and write media sample data."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "url": "/documentation/technologies",
      "kind": "technologies",
      "title": "Technologies"
    }
  },
  "diffAvailability": {
    "minor": {
      "change": "modified",
      "platform": "Xcode",
      "versions": [
        "13.1",
        "13.2 beta 1"
      ]
    },
    "major": {
      "change": "modified",
      "platform": "Xcode",
      "versions": [
        "13.0",
        "13.2 beta 1"
      ]
    }
  },
  "topicSections": [
    {
      "kind": "taskGroup",
      "title": "Media Reading",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avassetreader",
        "doc://com.apple.documentation/documentation/avfoundation/avassetreaderoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avassetreadertrackoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avassetreaderaudiomixoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avassetreadervideocompositionoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avassetreadersamplereferenceoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avassetreaderoutputmetadataadaptor"
      ],
      "anchor": "3643901"
    },
    {
      "kind": "taskGroup",
      "title": "Media Writing",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/writing_fragmented_mpeg-4_files_for_http_live_streaming",
        "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/tagging_media_with_video_color_information",
        "doc://com.apple.documentation/documentation/avfoundation/media_assets_and_metadata/sample-level_reading_and_writing/evaluating_an_app_s_video_color",
        "doc://com.apple.documentation/documentation/avfoundation/avoutputsettingsassistant",
        "doc://com.apple.documentation/documentation/avfoundation/avassetwriter",
        "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinput",
        "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputpixelbufferadaptor",
        "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputmetadataadaptor",
        "doc://com.apple.documentation/documentation/avfoundation/avassetwriterinputgroup"
      ],
      "anchor": "3643899"
    }
  ],
  "legalNotices": {
    "copyright": "Copyright &copy; 2021 Apple Inc. All rights reserved.",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy"
  }
}
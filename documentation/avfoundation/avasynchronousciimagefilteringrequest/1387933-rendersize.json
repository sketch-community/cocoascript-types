{
  "abstract": [
    {
      "type": "text",
      "text": "The width and height, in pixels, of the frame being processed."
    }
  ],
  "documentVersion": 0,
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/avfoundation",
        "doc://com.apple.documentation/documentation/avfoundation/media_composition_and_editing",
        "doc://com.apple.documentation/documentation/avfoundation/avvideocomposition",
        "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest"
      ]
    ]
  },
  "identifier": {
    "url": "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest/1387933-rendersize",
    "interfaceLanguage": "occ"
  },
  "legacy_identifier": 1387933,
  "kind": "symbol",
  "metadata": {
    "title": "renderSize",
    "role": "symbol",
    "roleHeading": "Instance Property",
    "modules": [
      {
        "name": "AVFoundation"
      }
    ],
    "platforms": [
      {
        "name": "iOS",
        "introducedAt": "9.0",
        "current": "15.2"
      },
      {
        "name": "iPadOS",
        "introducedAt": "9.0",
        "current": "15.2"
      },
      {
        "name": "macOS",
        "introducedAt": "10.11",
        "current": "12.1"
      },
      {
        "name": "Mac Catalyst",
        "introducedAt": "13.0",
        "current": "15.2"
      },
      {
        "name": "tvOS",
        "introducedAt": "9.0",
        "current": "15.2"
      }
    ],
    "externalID": "c:objc(cs)AVAsynchronousCIImageFilteringRequest(py)renderSize",
    "parent": {
      "title": "AVAsynchronousCIImageFilteringRequest"
    },
    "symbolKind": "instp"
  },
  "schemaVersion": {
    "major": 0,
    "minor": 1,
    "patch": 0
  },
  "sections": [],
  "variants": [
    {
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ],
      "paths": [
        "documentation/avfoundation/avasynchronousciimagefilteringrequest/1387933-rendersize"
      ]
    },
    {
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ],
      "paths": [
        "documentation/avfoundation/avasynchronousciimagefilteringrequest/1387933-rendersize"
      ]
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/avfoundation": {
      "title": "AVFoundation",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation",
      "url": "/documentation/avfoundation",
      "type": "topic",
      "kind": "symbol",
      "role": "collection"
    },
    "doc://com.apple.documentation/documentation/avfoundation/media_composition_and_editing": {
      "title": "Media Composition and Editing",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/media_composition_and_editing",
      "url": "/documentation/avfoundation/media_composition_and_editing",
      "type": "topic",
      "kind": "article",
      "role": "collectionGroup"
    },
    "doc://com.apple.documentation/documentation/avfoundation/avvideocomposition": {
      "title": "AVVideoComposition",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avvideocomposition",
      "url": "/documentation/avfoundation/avvideocomposition",
      "type": "topic",
      "kind": "symbol",
      "role": "symbol"
    },
    "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest": {
      "title": "AVAsynchronousCIImageFilteringRequest",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avasynchronousciimagefilteringrequest",
      "abstract": [
        {
          "type": "text",
          "text": "An object that supprts using Core Image filters to process an individual video frame in a video composition."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/coregraphics/cgsize": {
      "title": "CGSize",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/coregraphics/cgsize",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/coregraphics/cgsize"
    },
    "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest/1388240-compositiontime": {
      "title": "compositionTime",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest/1388240-compositiontime",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avasynchronousciimagefilteringrequest/1388240-compositiontime",
      "abstract": [
        {
          "type": "text",
          "text": "The time in the video composition corresponding to the frame being processed."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest/1387933-rendersize": {
      "title": "renderSize",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest/1387933-rendersize",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avasynchronousciimagefilteringrequest/1387933-rendersize",
      "abstract": [
        {
          "type": "text",
          "text": "The width and height, in pixels, of the frame being processed."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "url": "/documentation/technologies",
      "kind": "technologies",
      "title": "Technologies"
    }
  },
  "seeAlsoSections": [
    {
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avasynchronousciimagefilteringrequest/1388240-compositiontime"
      ],
      "title": "Getting Contextual Information for Filtering",
      "generated": true
    }
  ],
  "primaryContentSections": [
    {
      "kind": "declarations",
      "declarations": [
        {
          "languages": [
            "occ"
          ],
          "tokens": [
            {
              "kind": "keyword",
              "text": "@property"
            },
            {
              "kind": "text",
              "text": "(nonatomic, readonly) "
            },
            {
              "kind": "typeIdentifier",
              "preciseIdentifier": "c:@T@CGSize",
              "identifier": "doc://com.apple.documentation/documentation/coregraphics/cgsize",
              "text": "CGSize"
            },
            {
              "kind": "text",
              "text": " "
            },
            {
              "kind": "identifier",
              "text": "renderSize"
            },
            {
              "kind": "text",
              "text": ";"
            }
          ],
          "platforms": [
            "iOS",
            "iPadOS",
            "macOS",
            "Mac Catalyst",
            "tvOS"
          ]
        }
      ]
    },
    {
      "kind": "content",
      "content": [
        {
          "anchor": "discussion",
          "level": 2,
          "text": "Discussion",
          "type": "heading"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "You can use this property if you need to work with Core Image filters that apply transforms to the image."
            }
          ]
        }
      ]
    }
  ],
  "legalNotices": {
    "copyright": "Copyright &copy; 2021 Apple Inc. All rights reserved.",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy"
  }
}
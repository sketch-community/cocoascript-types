{
  "abstract": [
    {
      "type": "text",
      "text": "Visualize depth data in 2D and 3D from the TrueDepth camera."
    }
  ],
  "documentVersion": 0,
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/avfoundation",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture"
      ]
    ]
  },
  "identifier": {
    "url": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera",
    "interfaceLanguage": "occ"
  },
  "legacy_identifier": 2992014,
  "kind": "article",
  "metadata": {
    "title": "Streaming Depth Data from the TrueDepth Camera",
    "role": "sampleCode",
    "roleHeading": "Sample Code",
    "modules": [
      {
        "name": "AVFoundation"
      }
    ],
    "platforms": [
      {
        "name": "iOS",
        "introducedAt": "12.0",
        "current": "14.3"
      },
      {
        "name": "Xcode",
        "introducedAt": "11.0",
        "current": "12.3"
      }
    ]
  },
  "schemaVersion": {
    "major": 1,
    "minor": 0,
    "patch": 0
  },
  "sections": [],
  "variants": [
    {
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ],
      "paths": [
        "documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera"
      ]
    },
    {
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ],
      "paths": [
        "documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera"
      ]
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/avfoundation": {
      "title": "AVFoundation",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation",
      "url": "/documentation/avfoundation",
      "type": "topic",
      "kind": "symbol",
      "role": "collection"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture": {
      "title": "Cameras and Media Capture",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture",
      "url": "/documentation/avfoundation/cameras_and_media_capture",
      "type": "topic",
      "kind": "article",
      "role": "collectionGroup"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240488": {
      "title": "Listing 1",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240488",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240488"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240489": {
      "title": "Listing 2",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240489",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240489"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session": {
      "title": "Setting Up a Capture Session",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240490": {
      "title": "Listing 3",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240490",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240490"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240491": {
      "title": "Listing 4",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240491",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240491"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240492": {
      "title": "Listing 5",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240492",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240492"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240493": {
      "title": "Listing 6",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240493",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240493"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240495": {
      "title": "Listing 7",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240495",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240495"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240497": {
      "title": "Listing 8",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240497",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240497"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240498": {
      "title": "Listing 9",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240498",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240498"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240499": {
      "title": "Listing 10",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240499",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240499"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240501": {
      "title": "Listing 11",
      "type": "section",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240501",
      "kind": "article",
      "role": "codeListing",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera#3240501"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth": {
      "title": "Capturing Photos with Depth",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth",
      "abstract": [
        {
          "type": "text",
          "text": "Get a depth map with a photo to create effects like the system cameraâ€™s Portrait mode (on compatible devices)."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream": {
      "title": "AVCamFilter: Applying Filters to a Capture Stream",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream",
      "abstract": [
        {
          "type": "text",
          "text": "Render a capture stream with rose-colored filtering and depth effects."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera": {
      "title": "Streaming Depth Data from the TrueDepth Camera",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera",
      "abstract": [
        {
          "type": "text",
          "text": "Visualize depth data in 2D and 3D from the TrueDepth camera."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturedepthdataoutput": {
      "title": "AVCaptureDepthDataOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturedepthdataoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturedepthdataoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output that records scene depth information on compatible camera devices."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avdepthdata": {
      "title": "AVDepthData",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avdepthdata",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avdepthdata",
      "abstract": [
        {
          "type": "text",
          "text": "A container for per-pixel distance or disparity information captured by compatible camera devices."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avportraiteffectsmatte": {
      "title": "AVPortraitEffectsMatte",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avportraiteffectsmatte",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avportraiteffectsmatte",
      "abstract": [
        {
          "type": "text",
          "text": "An auxiliary image used to separate foreground from background with high resolution."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avsemanticsegmentationmatte": {
      "title": "AVSemanticSegmentationMatte",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avsemanticsegmentationmatte",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avsemanticsegmentationmatte",
      "abstract": [
        {
          "type": "text",
          "text": "An object that wraps a matting image for a particular semantic segmentation."
        }
      ]
    },
    "https://docs-assets.developer.apple.com/published/c117575374/StreamingDepthDataFromTheTrueDepthCamera.zip": {
      "type": "download",
      "identifier": "https://docs-assets.developer.apple.com/published/c117575374/StreamingDepthDataFromTheTrueDepthCamera.zip",
      "checksum": "997f00f705059ac4ac1a5622bbfd042de47a86a8883f8bbc703be039b243f5a9ca64b05c0642fb5c036e42b8c44712cc7aaf9f648c5e350aeae352c9b218f457",
      "url": "https://docs-assets.developer.apple.com/published/c117575374/StreamingDepthDataFromTheTrueDepthCamera.zip"
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "url": "/documentation/technologies",
      "kind": "technologies",
      "title": "Technologies"
    }
  },
  "sampleCodeDownload": {
    "action": {
      "overridingTitle": "Download",
      "type": "reference",
      "isActive": true,
      "identifier": "https://docs-assets.developer.apple.com/published/c117575374/StreamingDepthDataFromTheTrueDepthCamera.zip"
    }
  },
  "seeAlsoSections": [
    {
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturedepthdataoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avdepthdata",
        "doc://com.apple.documentation/documentation/avfoundation/avportraiteffectsmatte",
        "doc://com.apple.documentation/documentation/avfoundation/avsemanticsegmentationmatte"
      ],
      "title": "Depth Data Capture",
      "generated": true
    }
  ],
  "primaryContentSections": [
    {
      "kind": "content",
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The TrueDepth camera provides depth data in real time that allows you to determine the distance of a pixel from the front-facing camera. This sample demonstrates how to use the AVFoundation frameworkâ€™s capture API to read data from the TrueDepth camera, and how to display it in an intuitive fashion onscreen."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The sample shows two different views: a 2D view that distinguishes depth values by mapping depth to color, and a 3D view that renders data as a point cloud."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "To see this sample app in action, build and run the project in Xcode on an iOS device running iOS 11 or later. Because Xcode doesnâ€™t have access to the TrueDepth camera, this sample will not build or run in the Xcode simulator."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Set Up a Capture Session",
          "anchor": "3240504"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Set up an "
            },
            {
              "type": "codeVoice",
              "code": "AVCaptureSession"
            },
            {
              "type": "text",
              "text": " on a separate thread via the session queue. Initialize this session queue before configuring the camera for capture, like so:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "private let sessionQueue = DispatchQueue(label: \"session queue\", attributes: [], autoreleaseFrequency: .workItem)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240488",
            "title": "Listing 1"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "startRunning"
            },
            {
              "type": "text",
              "text": " method is a blocking call that may take time to execute. Dispatch session setup to the session queue so the main queue isnâ€™t blocked, allowing the appâ€™s UI to stay responsive:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "sessionQueue.async {",
            "    self.configureSession()",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240489",
            "title": "Listing 2"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Setting up the camera for video capture follows many of the same steps as normal video capture. See "
            },
            {
              "type": "reference",
              "isActive": true,
              "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session"
            },
            {
              "type": "text",
              "text": " for details on configuring streaming setup."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "On top of normal setup, request depth data by declaring a separate output:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "private let depthDataOutput = AVCaptureDepthDataOutput()"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240490",
            "title": "Listing 3"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Explicitly add this output type to your capture session:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "session.addOutput(depthDataOutput)",
            "depthDataOutput.isFilteringEnabled = false",
            "if let connection = depthDataOutput.connection(with: .depthData) {",
            "    connection.isEnabled = true",
            "} else {",
            "    print(\"No AVCaptureConnection\")",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240491",
            "title": "Listing 4"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Search for the highest resolution available with floating-point depth values, and lock the configuration to the format."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "let depthFormats = videoDevice.activeFormat.supportedDepthDataFormats",
            "let filtered = depthFormats.filter({",
            "    CMFormatDescriptionGetMediaSubType($0.formatDescription) == kCVPixelFormatType_DepthFloat16",
            "})",
            "let selectedFormat = filtered.max(by: {",
            "    first, second in CMVideoFormatDescriptionGetDimensions(first.formatDescription).width < CMVideoFormatDescriptionGetDimensions(second.formatDescription).width",
            "})",
            "",
            "do {",
            "    try videoDevice.lockForConfiguration()",
            "    videoDevice.activeDepthDataFormat = selectedFormat",
            "    videoDevice.unlockForConfiguration()",
            "} catch {",
            "    print(\"Could not lock device for configuration: \\(error)\")",
            "    setupResult = .configurationFailed",
            "    session.commitConfiguration()",
            "    return",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240492",
            "title": "Listing 5"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Synchronize the normal RGB video data with depth data output. The first output in the "
            },
            {
              "type": "codeVoice",
              "code": "dataOutputs"
            },
            {
              "type": "text",
              "text": " array is the master output."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "outputSynchronizer = AVCaptureDataOutputSynchronizer(dataOutputs: [videoDataOutput, depthDataOutput])",
            "outputSynchronizer!.setDelegate(self, queue: dataOutputQueue)"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240493",
            "title": "Listing 6"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The "
            },
            {
              "type": "codeVoice",
              "code": "CameraViewController"
            },
            {
              "type": "text",
              "text": " implementation creates and manages this session to interface with the camera. It also contains UI to toggle between the two viewing modes, 2D and 3D."
            }
          ]
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Visualize Depth Data in 2D",
          "anchor": "3240505"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The sample uses JET color coding to distinguish depth values, ranging from red (close) to blue (far). A slider controls the blending of the color code and the actual color values. Touching a pixel displays its depth value."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "codeVoice",
              "code": "DepthToJETConverter"
            },
            {
              "type": "text",
              "text": " performs the conversion. It separates the color spectrum into histogram bins, colors a Metal texture from depth values obtained in the image buffer, and renders that texture into the preview."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "var cvTextureOut: CVMetalTexture?",
            "CVMetalTextureCacheCreateTextureFromImage(kCFAllocatorDefault, textureCache, pixelBuffer, nil, textureFormat, width, height, 0, &cvTextureOut)",
            "guard let cvTexture = cvTextureOut, let texture = CVMetalTextureGetTexture(cvTexture) else {",
            "    print(\"Depth converter failed to create preview texture\")",
            "    CVMetalTextureCacheFlush(textureCache, 0)",
            "    return nil",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240495",
            "title": "Listing 7"
          }
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Visualize Depth Data in 3D",
          "anchor": "3240506"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The sampleâ€™s 3D viewer renders data as a point cloud. Control the camera with the following gestures:"
            }
          ]
        },
        {
          "type": "unorderedList",
          "items": [
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Pinch to zoom."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Pan to move the camera around the center."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Rotate with two fingers to turn the camera angle."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Double-tap the screen to reset the initial position."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The sample implements a 3D point cloud as a "
            },
            {
              "type": "codeVoice",
              "code": "PointCloudMetalView"
            },
            {
              "type": "text",
              "text": ". It uses a Metal vertex shader to control geometry and a Metal fragment shader to color individual vertices, keeping the depth texture and color texture separate:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "CVMetalTextureCacheRef _depthTextureCache;",
            "CVMetalTextureCacheRef _colorTextureCache;"
          ],
          "syntax": "occ",
          "metadata": {
            "anchor": "3240497",
            "title": "Listing 8"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The depth frameâ€™s depth map provides the basis for the Metal viewâ€™s depth texture:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "CVPixelBufferRef depthFrame = depthData.depthDataMap;",
            "CVMetalTextureRef cvDepthTexture = nullptr;",
            "if (kCVReturnSuccess != CVMetalTextureCacheCreateTextureFromImage(kCFAllocatorDefault,",
            "                        _depthTextureCache,",
            "                        depthFrame,",
            "                        nil,",
            "                        MTLPixelFormatR16Float,",
            "                        CVPixelBufferGetWidth(depthFrame),",
            "                        CVPixelBufferGetHeight(depthFrame),",
            "                        0,",
            "                        &cvDepthTexture)) {",
            "    NSLog(@\"Failed to create depth texture\");",
            "    CVPixelBufferRelease(colorFrame);",
            "    return;",
            "}",
            "",
            "id<MTLTexture> depthTexture = CVMetalTextureGetTexture(cvDepthTexture);"
          ],
          "syntax": "occ",
          "metadata": {
            "anchor": "3240498",
            "title": "Listing 9"
          }
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The RGB image provides the basis for the Metal viewâ€™s color texture:"
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "CVMetalTextureRef cvColorTexture = nullptr;",
            "if (kCVReturnSuccess != CVMetalTextureCacheCreateTextureFromImage(kCFAllocatorDefault,",
            "                        _colorTextureCache,",
            "                        colorFrame,",
            "                        nil,",
            "                        MTLPixelFormatBGRA8Unorm,",
            "                        CVPixelBufferGetWidth(colorFrame),",
            "                        CVPixelBufferGetHeight(colorFrame),",
            "                        0,",
            "                        &cvColorTexture)) {",
            "    NSLog(@\"Failed to create color texture\");",
            "    CVPixelBufferRelease(colorFrame);",
            "    return;",
            "}",
            "",
            "id<MTLTexture> colorTexture = CVMetalTextureGetTexture(cvColorTexture);"
          ],
          "syntax": "occ",
          "metadata": {
            "anchor": "3240499",
            "title": "Listing 10"
          }
        },
        {
          "level": 3,
          "type": "heading",
          "text": "Track Thermal State",
          "anchor": "3240507"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "Processing depth data from a live stream may cause the device to heat up. Keep tabs on the thermal state so you can alert the user if it exceeds a dangerous threshold."
            }
          ]
        },
        {
          "type": "codeListing",
          "code": [
            "@objc",
            "func thermalStateChanged(notification: NSNotification) {",
            "    if let processInfo = notification.object as? ProcessInfo {",
            "        showThermalState(state: processInfo.thermalState)",
            "    }",
            "}",
            "",
            "func showThermalState(state: ProcessInfo.ThermalState) {",
            "    DispatchQueue.main.async {",
            "        var thermalStateString = \"UNKNOWN\"",
            "        if state == .nominal {",
            "            thermalStateString = \"NOMINAL\"",
            "        } else if state == .fair {",
            "            thermalStateString = \"FAIR\"",
            "        } else if state == .serious {",
            "            thermalStateString = \"SERIOUS\"",
            "        } else if state == .critical {",
            "            thermalStateString = \"CRITICAL\"",
            "        }",
            "        ",
            "        let message = NSLocalizedString(\"Thermal state: \\(thermalStateString)\", comment: \"Alert message when thermal state has changed\")",
            "        let alertController = UIAlertController(title: \"TrueDepthStreamer\", message: message, preferredStyle: .alert)",
            "        alertController.addAction(UIAlertAction(title: NSLocalizedString(\"OK\", comment: \"Alert OK button\"), style: .cancel, handler: nil))",
            "        self.present(alertController, animated: true, completion: nil)",
            "    }",
            "}"
          ],
          "syntax": "swift",
          "metadata": {
            "anchor": "3240501",
            "title": "Listing 11"
          }
        }
      ]
    }
  ],
  "legalNotices": {
    "copyright": "Copyright &copy; 2020 Apple Inc. All rights reserved.",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy"
  }
}
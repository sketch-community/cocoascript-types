{
  "abstract": [
    {
      "type": "text",
      "text": "Capture photos and record video and audio; configure built-in cameras and microphones or external capture devices."
    }
  ],
  "documentVersion": 0,
  "hierarchy": {
    "paths": [
      [
        "doc://com.apple.documentation/documentation/technologies",
        "doc://com.apple.documentation/documentation/avfoundation"
      ]
    ]
  },
  "identifier": {
    "url": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture",
    "interfaceLanguage": "occ"
  },
  "legacy_identifier": 2863969,
  "kind": "symbol",
  "metadata": {
    "title": "Cameras and Media Capture",
    "role": "collectionGroup",
    "modules": [
      {
        "name": "AVFoundation"
      }
    ]
  },
  "schemaVersion": {
    "major": 0,
    "minor": 1,
    "patch": 0
  },
  "sections": [],
  "variants": [
    {
      "traits": [
        {
          "interfaceLanguage": "occ"
        }
      ],
      "paths": [
        "documentation/avfoundation/cameras_and_media_capture"
      ]
    },
    {
      "traits": [
        {
          "interfaceLanguage": "swift"
        }
      ],
      "paths": [
        "documentation/avfoundation/cameras_and_media_capture"
      ]
    }
  ],
  "references": {
    "doc://com.apple.documentation/documentation/avfoundation": {
      "title": "AVFoundation",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation",
      "url": "/documentation/avfoundation",
      "type": "topic",
      "kind": "symbol",
      "role": "collection"
    },
    "doc://com.apple.documentation/documentation/uikit/uiimagepickercontroller": {
      "title": "UIImagePickerController",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/uikit/uiimagepickercontroller",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/uikit/uiimagepickercontroller"
    },
    "link-media-2970476": {
      "identifier": "link-media-2970476",
      "type": "link",
      "title": "Figure 1",
      "url": "/documentation/avfoundation/cameras_and_media_capture#2970476"
    },
    "media-2970476": {
      "identifier": "media-2970476",
      "type": "image",
      "variants": [
        {
          "traits": [
            "2x"
          ],
          "size": {
            "width": 543,
            "height": 90
          },
          "url": "https://docs-assets.developer.apple.com/published/058e665a6c/4ecf0924-ea2b-4faa-aea8-7bfc0b3fe419.png"
        },
        {
          "traits": [
            "1x"
          ],
          "size": {
            "width": 543,
            "height": 90
          },
          "url": "https://docs-assets.developer.apple.com/published/917b2fd9cf/47df73b5-5cba-4c41-894d-b0a2fb600d1c.png"
        }
      ],
      "alt": "Block diagram of the basic capture session architecture: an AVCaptureSession acquires data from an AVCaptureDevice through AVCaptureDeviceInput, and provides data to one or more AVCaptureOutput objects.",
      "title": "Figure 1"
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_ios": {
      "title": "Requesting Authorization for Media Capture on iOS",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_ios",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_ios",
      "abstract": [
        {
          "type": "text",
          "text": "Respect user privacy by seeking permission to capture and store photos, audio, and video."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_macos": {
      "title": "Requesting Authorization for Media Capture on macOS",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_macos",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_macos",
      "abstract": [
        {
          "type": "text",
          "text": "Prompt the user to authorize access to the camera and microphone."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session": {
      "title": "Setting Up a Capture Session",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session",
      "abstract": [
        {
          "type": "text",
          "text": "Configure input devices, output media, preview views, and basic settings before capturing photos or video."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avkit/accessing_the_camera_while_multitasking": {
      "title": "Accessing the Camera While Multitasking",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avkit/accessing_the_camera_while_multitasking",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avkit/accessing_the_camera_while_multitasking",
      "abstract": [
        {
          "type": "text",
          "text": "Operate the camera in Split View, Slide Over, or Picture in Picture mode."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcam_building_a_camera_app": {
      "title": "AVCam: Building a Camera App",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcam_building_a_camera_app",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/cameras_and_media_capture/avcam_building_a_camera_app",
      "abstract": [
        {
          "type": "text",
          "text": "Capture photos with depth data and record video using the front and rear iPhone and iPad cameras."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avmulticampip_capturing_from_multiple_cameras": {
      "title": "AVMultiCamPiP: Capturing from Multiple Cameras",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avmulticampip_capturing_from_multiple_cameras",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/cameras_and_media_capture/avmulticampip_capturing_from_multiple_cameras",
      "abstract": [
        {
          "type": "text",
          "text": "Simultaneously record the output from the front and back cameras into a single movie file by using a multi-camera capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcambarcode_detecting_barcodes_and_faces": {
      "title": "AVCamBarcode: Detecting Barcodes and Faces",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcambarcode_detecting_barcodes_and_faces",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/cameras_and_media_capture/avcambarcode_detecting_barcodes_and_faces",
      "abstract": [
        {
          "type": "text",
          "text": "Identify machine readable codes or faces by using the camera."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturesession": {
      "title": "AVCaptureSession",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturesession",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturesession",
      "abstract": [
        {
          "type": "text",
          "text": "An object that manages capture activity and coordinates the flow of data from input devices to capture outputs."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturemulticamsession": {
      "title": "AVCaptureMultiCamSession",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturemulticamsession",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturemulticamsession",
      "abstract": [
        {
          "type": "text",
          "text": "A capture session that supports simultaneous capture from multiple inputs of the same media type."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/choosing_a_capture_device": {
      "title": "Choosing a Capture Device",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/choosing_a_capture_device",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/choosing_a_capture_device",
      "abstract": [
        {
          "type": "text",
          "text": "Select the front or back camera, or use advanced features like the TrueDepth camera or dual camera."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturedevice": {
      "title": "AVCaptureDevice",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturedevice",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturedevice",
      "abstract": [
        {
          "type": "text",
          "text": "A device that provides input (such as audio or video) for capture sessions and offers controls for hardware-specific capture features."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturedeviceinput": {
      "title": "AVCaptureDeviceInput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturedeviceinput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturedeviceinput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture input that provides media from a capture device to a capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_still_and_live_photos": {
      "title": "Capturing Still and Live Photos",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_still_and_live_photos",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/capturing_still_and_live_photos",
      "abstract": [
        {
          "type": "text",
          "text": "Configure and capture single or multiple still images, Live Photos, and other forms of photography."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_in_raw_and_apple_proraw_formats": {
      "title": "Capturing Photos in RAW and Apple ProRAW Formats",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_in_raw_and_apple_proraw_formats",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/capturing_photos_in_raw_and_apple_proraw_formats",
      "abstract": [
        {
          "type": "text",
          "text": "Support professional photography workflows by enabling minimally processed image capture in your camera app."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/appkit/supporting_continuity_camera_in_your_mac_app": {
      "title": "Supporting Continuity Camera in Your Mac App",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/appkit/supporting_continuity_camera_in_your_mac_app",
      "kind": "article",
      "role": "article",
      "url": "/documentation/appkit/supporting_continuity_camera_in_your_mac_app",
      "abstract": [
        {
          "type": "text",
          "text": "Incorporate scanned documents and pictures from a user's iPhone, iPad, or iPod touch into your Mac app using Continuity Camera."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturephoto": {
      "title": "AVCapturePhoto",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturephoto",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturephoto",
      "abstract": [
        {
          "type": "text",
          "text": "A container for image data from a photo capture output."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturephotooutput": {
      "title": "AVCapturePhotoOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturephotooutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturephotooutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output for still image, Live Photos, and other photography workflows."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturephotocapturedelegate": {
      "title": "AVCapturePhotoCaptureDelegate",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturephotocapturedelegate",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturephotocapturedelegate",
      "abstract": [
        {
          "type": "text",
          "text": "Methods for monitoring progress and receiving results from a photo capture output."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth": {
      "title": "Capturing Photos with Depth",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth",
      "abstract": [
        {
          "type": "text",
          "text": "Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices)."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream": {
      "title": "AVCamFilter: Applying Filters to a Capture Stream",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream",
      "abstract": [
        {
          "type": "text",
          "text": "Render a capture stream with rose-colored filtering and depth effects."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera": {
      "title": "Streaming Depth Data from the TrueDepth Camera",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera",
      "kind": "article",
      "role": "sampleCode",
      "url": "/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera",
      "abstract": [
        {
          "type": "text",
          "text": "Visualize depth data in 2D and 3D from the TrueDepth camera."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturedepthdataoutput": {
      "title": "AVCaptureDepthDataOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturedepthdataoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturedepthdataoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output that records scene depth information on compatible camera devices."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avdepthdata": {
      "title": "AVDepthData",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avdepthdata",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avdepthdata",
      "abstract": [
        {
          "type": "text",
          "text": "A container for per-pixel distance or disparity information captured by compatible camera devices."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avportraiteffectsmatte": {
      "title": "AVPortraitEffectsMatte",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avportraiteffectsmatte",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avportraiteffectsmatte",
      "abstract": [
        {
          "type": "text",
          "text": "An auxiliary image used to separate foreground from background with high resolution."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avsemanticsegmentationmatte": {
      "title": "AVSemanticSegmentationMatte",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avsemanticsegmentationmatte",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avsemanticsegmentationmatte",
      "abstract": [
        {
          "type": "text",
          "text": "An object that wraps a matting image for a particular semantic segmentation."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_video_in_alternative_formats": {
      "title": "Capturing Video in Alternative Formats",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_video_in_alternative_formats",
      "kind": "article",
      "role": "article",
      "url": "/documentation/avfoundation/cameras_and_media_capture/capturing_video_in_alternative_formats",
      "abstract": [
        {
          "type": "text",
          "text": "Change the format used for capturing movie files."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturemoviefileoutput": {
      "title": "AVCaptureMovieFileOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturemoviefileoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturemoviefileoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output that records video and audio to a QuickTime movie file."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturevideodataoutput": {
      "title": "AVCaptureVideoDataOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturevideodataoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturevideodataoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output that records video and provides access to video frames for processing."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiofileoutput": {
      "title": "AVCaptureAudioFileOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiofileoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcaptureaudiofileoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output that records audio and saves the recorded audio to a file."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiodataoutput": {
      "title": "AVCaptureAudioDataOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiodataoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcaptureaudiodataoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output that records audio and provides access to audio sample buffers as they are recorded. "
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadatabodyobject": {
      "title": "AVMetadataBodyObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadatabodyobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadatabodyobject",
      "abstract": [
        {
          "type": "text",
          "text": "An abstract class that defines the interface for a metadata body object."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadatacatbodyobject": {
      "title": "AVMetadataCatBodyObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadatacatbodyobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadatacatbodyobject",
      "abstract": [
        {
          "type": "text",
          "text": "An object representing a single detected cat body in a picture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadatadogbodyobject": {
      "title": "AVMetadataDogBodyObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadatadogbodyobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadatadogbodyobject",
      "abstract": [
        {
          "type": "text",
          "text": "An object representing a single detected dog body in a picture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadatahumanbodyobject": {
      "title": "AVMetadataHumanBodyObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadatahumanbodyobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadatahumanbodyobject",
      "abstract": [
        {
          "type": "text",
          "text": "An object representing a single detected human body in a picture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadatasalientobject": {
      "title": "AVMetadataSalientObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadatasalientobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadatasalientobject",
      "abstract": [
        {
          "type": "text",
          "text": "An object representing a single salient area in a picture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturemetadatainput": {
      "title": "AVCaptureMetadataInput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturemetadatainput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturemetadatainput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture input for providing timed metadata to a capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturemetadataoutput": {
      "title": "AVCaptureMetadataOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturemetadataoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturemetadataoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output for processing timed metadata produced by a capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadatafaceobject": {
      "title": "AVMetadataFaceObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadatafaceobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadatafaceobject",
      "abstract": [
        {
          "type": "text",
          "text": "Face information detected by a metadata capture output."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadatamachinereadablecodeobject": {
      "title": "AVMetadataMachineReadableCodeObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadatamachinereadablecodeobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadatamachinereadablecodeobject",
      "abstract": [
        {
          "type": "text",
          "text": "Barcode information detected by a metadata capture output."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avmetadataobject": {
      "title": "AVMetadataObject",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avmetadataobject",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avmetadataobject",
      "abstract": [
        {
          "type": "text",
          "text": "The abstract superclass for objects provided by a metadata capture output."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturedataoutputsynchronizer": {
      "title": "AVCaptureDataOutputSynchronizer",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturedataoutputsynchronizer",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturedataoutputsynchronizer",
      "abstract": [
        {
          "type": "text",
          "text": "An object that coordinates time-matched delivery of data from multiple capture outputs."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddatacollection": {
      "title": "AVCaptureSynchronizedDataCollection",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddatacollection",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturesynchronizeddatacollection",
      "abstract": [
        {
          "type": "text",
          "text": "A set of data samples collected simultaneously from multiple capture outputs."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddepthdata": {
      "title": "AVCaptureSynchronizedDepthData",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddepthdata",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturesynchronizeddepthdata",
      "abstract": [
        {
          "type": "text",
          "text": "A container for scene depth information collected using synchronized capture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata": {
      "title": "AVCaptureSynchronizedMetadataObjectData",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata",
      "abstract": [
        {
          "type": "text",
          "text": "A container for metadata objects collected using synchronized capture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizedsamplebufferdata": {
      "title": "AVCaptureSynchronizedSampleBufferData",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizedsamplebufferdata",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturesynchronizedsamplebufferdata",
      "abstract": [
        {
          "type": "text",
          "text": "A container for video or audio samples collected using synchronized capture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddata": {
      "title": "AVCaptureSynchronizedData",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddata",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturesynchronizeddata",
      "abstract": [
        {
          "type": "text",
          "text": "The abstract superclass for media samples collected using synchronized capture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturevideopreviewlayer": {
      "title": "AVCaptureVideoPreviewLayer",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturevideopreviewlayer",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturevideopreviewlayer",
      "abstract": [
        {
          "type": "text",
          "text": "A Core Animation layer that displays the video as it’s captured."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiopreviewoutput": {
      "title": "AVCaptureAudioPreviewOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiopreviewoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcaptureaudiopreviewoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output that provides preview playback for audio being recorded in a capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturescreeninput": {
      "title": "AVCaptureScreenInput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturescreeninput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturescreeninput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture input for recording from a screen in macOS. "
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturestillimageoutput": {
      "title": "AVCaptureStillImageOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturestillimageoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturestillimageoutput",
      "abstract": [
        {
          "type": "text",
          "text": "A capture output for capturing still photos in macOS."
        }
      ],
      "deprecated": true
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcaptureinput": {
      "title": "AVCaptureInput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcaptureinput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcaptureinput",
      "abstract": [
        {
          "type": "text",
          "text": "The abstract superclass for objects that provide input data to a capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcaptureoutput": {
      "title": "AVCaptureOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcaptureoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcaptureoutput",
      "abstract": [
        {
          "type": "text",
          "text": "The abstract superclass for objects that output the media recorded in a capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcaptureconnection": {
      "title": "AVCaptureConnection",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcaptureconnection",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcaptureconnection",
      "abstract": [
        {
          "type": "text",
          "text": "A connection between a specific pair of capture input and capture output objects in a capture session."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiochannel": {
      "title": "AVCaptureAudioChannel",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiochannel",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcaptureaudiochannel",
      "abstract": [
        {
          "type": "text",
          "text": "An object that monitors average and peak power levels for an audio channel in a capture connection."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutput": {
      "title": "AVCaptureFileOutput",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutput",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturefileoutput",
      "abstract": [
        {
          "type": "text",
          "text": "The abstract superclass for capture outputs that can record captured data to a file."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutputdelegate": {
      "title": "AVCaptureFileOutputDelegate",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutputdelegate",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturefileoutputdelegate",
      "abstract": [
        {
          "type": "text",
          "text": "Methods for monitoring or controlling the output of a media file capture."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutputrecordingdelegate": {
      "title": "AVCaptureFileOutputRecordingDelegate",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutputrecordingdelegate",
      "kind": "symbol",
      "role": "symbol",
      "url": "/documentation/avfoundation/avcapturefileoutputrecordingdelegate",
      "abstract": [
        {
          "type": "text",
          "text": "Methods for responding to events that occur while recording captured media to a file."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture": {
      "title": "Cameras and Media Capture",
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture",
      "kind": "article",
      "role": "collectionGroup",
      "url": "/documentation/avfoundation/cameras_and_media_capture",
      "abstract": [
        {
          "type": "text",
          "text": "Capture photos and record video and audio; configure built-in cameras and microphones or external capture devices."
        }
      ]
    },
    "doc://com.apple.documentation/documentation/technologies": {
      "type": "topic",
      "identifier": "doc://com.apple.documentation/documentation/technologies",
      "url": "/documentation/technologies",
      "kind": "technologies",
      "title": "Technologies"
    }
  },
  "diffAvailability": {
    "major": {
      "change": "modified",
      "platform": "Xcode",
      "versions": [
        "13.0",
        "13.2 beta 1"
      ]
    }
  },
  "topicSections": [
    {
      "kind": "taskGroup",
      "title": "User Privacy",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_ios",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/requesting_authorization_for_media_capture_on_macos"
      ],
      "anchor": "3197348"
    },
    {
      "kind": "taskGroup",
      "title": "Capture Sessions",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/setting_up_a_capture_session",
        "doc://com.apple.documentation/documentation/avkit/accessing_the_camera_while_multitasking",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcam_building_a_camera_app",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avmulticampip_capturing_from_multiple_cameras",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcambarcode_detecting_barcodes_and_faces",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturesession",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturemulticamsession"
      ],
      "anchor": "2865435"
    },
    {
      "kind": "taskGroup",
      "title": "Capture Devices",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/choosing_a_capture_device",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturedevice",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturedeviceinput"
      ],
      "anchor": "2958848"
    },
    {
      "kind": "taskGroup",
      "title": "Photo Capture",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_still_and_live_photos",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_in_raw_and_apple_proraw_formats",
        "doc://com.apple.documentation/documentation/appkit/supporting_continuity_camera_in_your_mac_app",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturephoto",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturephotooutput",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturephotocapturedelegate"
      ],
      "anchor": "2865436"
    },
    {
      "kind": "taskGroup",
      "title": "Depth Data Capture",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_photos_with_depth",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/avcamfilter_applying_filters_to_a_capture_stream",
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/streaming_depth_data_from_the_truedepth_camera",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturedepthdataoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avdepthdata",
        "doc://com.apple.documentation/documentation/avfoundation/avportraiteffectsmatte",
        "doc://com.apple.documentation/documentation/avfoundation/avsemanticsegmentationmatte"
      ],
      "anchor": "2877303"
    },
    {
      "kind": "taskGroup",
      "title": "Movie and Video Capture",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/cameras_and_media_capture/capturing_video_in_alternative_formats",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturemoviefileoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturevideodataoutput"
      ],
      "anchor": "2865438"
    },
    {
      "kind": "taskGroup",
      "title": "Audio Capture",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiofileoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiodataoutput"
      ],
      "anchor": "2865439"
    },
    {
      "kind": "taskGroup",
      "title": "Metadata Capture",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avmetadatabodyobject",
        "doc://com.apple.documentation/documentation/avfoundation/avmetadatacatbodyobject",
        "doc://com.apple.documentation/documentation/avfoundation/avmetadatadogbodyobject",
        "doc://com.apple.documentation/documentation/avfoundation/avmetadatahumanbodyobject",
        "doc://com.apple.documentation/documentation/avfoundation/avmetadatasalientobject",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturemetadatainput",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturemetadataoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avmetadatafaceobject",
        "doc://com.apple.documentation/documentation/avfoundation/avmetadatamachinereadablecodeobject",
        "doc://com.apple.documentation/documentation/avfoundation/avmetadataobject"
      ],
      "anchor": "2865440"
    },
    {
      "kind": "taskGroup",
      "title": "Synchronized Capture",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avcapturedataoutputsynchronizer",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddatacollection",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddepthdata",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizedsamplebufferdata",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturesynchronizeddata"
      ],
      "anchor": "2877304"
    },
    {
      "kind": "taskGroup",
      "title": "Media Capture Preview",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avcapturevideopreviewlayer",
        "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiopreviewoutput"
      ],
      "anchor": "2865441"
    },
    {
      "kind": "taskGroup",
      "title": "Mac Capture Options",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avcapturescreeninput",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturestillimageoutput"
      ],
      "anchor": "2865442"
    },
    {
      "kind": "taskGroup",
      "title": "Session Configuration",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avcaptureinput",
        "doc://com.apple.documentation/documentation/avfoundation/avcaptureoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avcaptureconnection",
        "doc://com.apple.documentation/documentation/avfoundation/avcaptureaudiochannel"
      ],
      "anchor": "2865444"
    },
    {
      "kind": "taskGroup",
      "title": "File Output",
      "identifiers": [
        "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutput",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutputdelegate",
        "doc://com.apple.documentation/documentation/avfoundation/avcapturefileoutputrecordingdelegate"
      ],
      "anchor": "2870877"
    }
  ],
  "primaryContentSections": [
    {
      "kind": "content",
      "content": [
        {
          "anchor": "overview",
          "level": 2,
          "text": "Overview",
          "type": "heading"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The AVFoundation Capture subsystem provides a common high-level architecture for video, photo, and audio capture services in iOS and macOS. Use this system if you want to:"
            }
          ]
        },
        {
          "type": "unorderedList",
          "items": [
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Build a custom camera UI to integrate shooting photos or videos into your app’s user experience."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Give users more direct control over photo and video capture, such as focus, exposure, and stabilization options."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Produce different results than the system camera UI, such as RAW format photos, depth maps, or videos with custom timed metadata."
                    }
                  ]
                }
              ]
            },
            {
              "content": [
                {
                  "type": "paragraph",
                  "inlineContent": [
                    {
                      "type": "text",
                      "text": "Get live access to pixel or audio data streaming directly from a capture device."
                    }
                  ]
                }
              ]
            }
          ]
        },
        {
          "type": "aside",
          "content": [
            {
              "type": "paragraph",
              "inlineContent": [
                {
                  "type": "text",
                  "text": "To instead let the user capture media with the system camera UI within your app, see "
                },
                {
                  "type": "reference",
                  "isActive": true,
                  "identifier": "doc://com.apple.documentation/documentation/uikit/uiimagepickercontroller"
                },
                {
                  "type": "text",
                  "text": "."
                }
              ]
            }
          ],
          "style": "note",
          "name": "Note"
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "text",
              "text": "The main parts of the capture architecture are sessions, inputs, and outputs: Capture sessions connect one or more inputs to one or more outputs. Inputs are sources of media, including capture devices like the cameras and microphones built into an iOS device or Mac. Outputs acquire media from inputs to produce useful data, such as movie files written to disk or raw pixel buffers available for live processing."
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": [
            {
              "type": "image",
              "identifier": "media-2970476",
              "metadata": {
                "anchor": "2970476",
                "title": "Figure 1"
              }
            }
          ]
        },
        {
          "type": "paragraph",
          "inlineContent": []
        }
      ]
    }
  ],
  "legalNotices": {
    "copyright": "Copyright &copy; 2021 Apple Inc. All rights reserved.",
    "termsOfUse": "https://www.apple.com/legal/internet-services/terms/site.html",
    "privacyPolicy": "https://www.apple.com/privacy/privacy-policy"
  }
}